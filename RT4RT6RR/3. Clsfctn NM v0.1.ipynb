{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_0 = pd.read_csv(r\"C:\\Users\\pingk\\Downloads\\fadhli nitip\\asik_rt4_NWIN_CLND_BLNCD_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regions of interest\n",
    "regions_of_interest = [\n",
    "    (2986, 3026), (2933, 2973), (2902, 2942), (2833, 2873),\n",
    "    (1480, 2020), (1445, 1485), (1398, 1438), (1358, 1398),\n",
    "    (1215, 1255), (1140, 1180), (1096, 1136), (1078, 1118),\n",
    "    (1000, 910), (702, 742)\n",
    "]\n",
    "\n",
    "# Extract columns corresponding to the regions of interest\n",
    "columns_to_focus = []\n",
    "for start, end in regions_of_interest:\n",
    "    columns_to_focus.extend([col for col in df_0.columns[4:-7] if start <= float(col) <= end])\n",
    "\n",
    "# Create a new DataFrame with the selected regions\n",
    "df_0_selected_regions = df_0[columns_to_focus]\n",
    "\n",
    "# Combine the selected regions with the target column and other relevant columns\n",
    "df_0_selected_regions = pd.concat([df_0[['thnoth_name', 'prov_char']], df_0_selected_regions], axis=1)\n",
    "\n",
    "# Save the DataFrame for further processing\n",
    "#df_0_selected_regions.to_csv('data/data file 2/data_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_selected_regions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Function for baseline correction with dynamic window length\n",
    "def baseline_correction(spectrum, default_window_length=15, polyorder=3):\n",
    "    spectrum_length = len(spectrum)\n",
    "    if spectrum_length < default_window_length:\n",
    "        window_length = spectrum_length // 2 * 2 + 1  # Make window length odd and less than the size of the spectrum\n",
    "    else:\n",
    "        window_length = default_window_length\n",
    "    baseline = savgol_filter(spectrum, window_length, polyorder, mode='nearest')\n",
    "    corrected_spectrum = spectrum - baseline\n",
    "    return corrected_spectrum\n",
    "\n",
    "# Apply baseline correction\n",
    "df_baseline_corrected_v0 = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_baseline_corrected_v0[col] = baseline_correction(df_baseline_corrected_v0[col])\n",
    "\n",
    "# Save the baseline corrected data\n",
    "# df_baseline_corrected_v0.to_csv('data/data file 2/data_1_bslcrct.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavGol Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Savitzky-Golay smoothing\n",
    "def savitzky_golay_smoothing(spectrum, default_window_length=11, polyorder=2):\n",
    "    window_length = min(default_window_length, len(spectrum) // 2 * 2 + 1)  # Make window length odd and less than or equal to the size of the spectrum\n",
    "    if window_length < 3:  # Ensure window length is at least 3\n",
    "        window_length = 3\n",
    "    return savgol_filter(spectrum, window_length, polyorder, mode='nearest')  # Set mode to 'nearest'\n",
    "\n",
    "# Apply smoothing\n",
    "df_smoothed_v0 = df_baseline_corrected_v0.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_smoothed_v0[col] = savitzky_golay_smoothing(df_smoothed_v0[col])\n",
    "\n",
    "# Save the smoothed data\n",
    "# df_smoothed_v0.to_csv('data/data file 2/data_1_smoothed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for normalization (Min-Max scaling)\n",
    "def min_max_normalization(spectrum):\n",
    "    return (spectrum - np.min(spectrum)) / (np.max(spectrum) - np.min(spectrum))\n",
    "\n",
    "# Apply normalization\n",
    "df_normalized_v0 = df_smoothed_v0.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_normalized_v0[col] = min_max_normalization(df_normalized_v0[col])\n",
    "\n",
    "# Save the normalized data\n",
    "# df_normalized_v0.to_csv('data/data file 2/data_1_normalized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatization (np.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first derivative using np.gradient\n",
    "data_spectrum = df_normalized_v0.iloc[:, 2:].values\n",
    "first_derivative_np = np.gradient(data_spectrum, axis=1)\n",
    "\n",
    "# Calculate the second derivative using np.gradient\n",
    "second_derivative_np = np.gradient(first_derivative_np, axis=1)\n",
    "\n",
    "# Convert the results back to DataFrame\n",
    "data_1_der_np = pd.DataFrame(first_derivative_np, columns=df_normalized_v0.columns[2:])\n",
    "data_2_der_np = pd.DataFrame(second_derivative_np, columns=df_normalized_v0.columns[2:])\n",
    "\n",
    "# Combine the first two columns from the original dataset with the np.gradient derivatives\n",
    "\n",
    "# Extract the first two columns\n",
    "first_two_columns = df_normalized_v0.iloc[:, :2]\n",
    "\n",
    "# Combine the first two columns with the derivatives\n",
    "data_1_der_combined = pd.concat([first_two_columns, data_1_der_np], axis=1)\n",
    "data_2_der_combined = pd.concat([first_two_columns, data_2_der_np], axis=1)\n",
    "\n",
    "# Export the combined data to CSV\n",
    "# data_1_der_combined.to_csv('data/data file 2/data_1_1_der.csv', index=False)\n",
    "# data_2_der_combined.to_csv('data/data file 2/data_1_2_der.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatization (SavGol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spectrum data\n",
    "data_spectrum = df_normalized_v0.iloc[:, 2:].values\n",
    "\n",
    "# Apply Savitzky-Golay filter for the first derivative\n",
    "first_derivative_savgol = savgol_filter(data_spectrum, window_length=5, polyorder=2, deriv=1, axis=1)\n",
    "\n",
    "# Apply Savitzky-Golay filter for the second derivative\n",
    "second_derivative_savgol = savgol_filter(data_spectrum, window_length=5, polyorder=2, deriv=2, axis=1)\n",
    "\n",
    "# Convert the results back to DataFrame\n",
    "data_1_der_savgol = pd.DataFrame(first_derivative_savgol, columns=df_normalized_v0.columns[2:])\n",
    "data_2_der_savgol = pd.DataFrame(second_derivative_savgol, columns=df_normalized_v0.columns[2:])\n",
    "\n",
    "# Extract the first two columns\n",
    "first_two_columns = df_normalized_v0.iloc[:, :2]\n",
    "\n",
    "# Combine the first two columns with the Savitzky-Golay derivatives\n",
    "data_1_der_savgol_combined = pd.concat([first_two_columns, data_1_der_savgol], axis=1)\n",
    "data_2_der_savgol_combined = pd.concat([first_two_columns, data_2_der_savgol], axis=1)\n",
    "\n",
    "# Export the combined data to CSV\n",
    "# data_1_der_savgol_combined.to_csv('data/data file 2/data_1_1_der_savgol.csv', index=False)\n",
    "# data_2_der_savgol_combined.to_csv('data/data file 2/data_1_2_der_savgol.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snv(spectrum):\n",
    "    return (spectrum - np.mean(spectrum)) / np.std(spectrum)\n",
    "\n",
    "# Apply SNV to the selected regions\n",
    "df_snv = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_snv[col] = snv(df_snv[col])\n",
    "\n",
    "# Save the SNV data\n",
    "# df_snv.to_csv('data/data file 2/data_1_snv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Normal Variate (RNV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnv(spectrum):\n",
    "    random_noise = np.random.normal(0, np.std(spectrum), spectrum.shape)\n",
    "    return spectrum + random_noise\n",
    "\n",
    "# Apply RNV to the selected regions\n",
    "df_rnv = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_rnv[col] = rnv(df_rnv[col])\n",
    "\n",
    "# Save the RNV data\n",
    "# df_rnv.to_csv('data/data file 2/data_1_rnv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplicative Scatter Correction (MSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def msc(spectrum, reference):\n",
    "#     mean_spectrum = np.mean(reference, axis=0)\n",
    "#     fit = np.polyfit(mean_spectrum, spectrum, 1, full=True)\n",
    "#     corrected_spectrum = (spectrum - fit[0][1]) / fit[0][0]\n",
    "#     return corrected_spectrum\n",
    "\n",
    "# # Apply MSC to the selected regions\n",
    "# df_msc = df_0_selected_regions.copy()\n",
    "# for col in columns_to_focus:\n",
    "#     df_msc[col] = msc(df_msc[col])\n",
    "\n",
    "# # Save the MSC data\n",
    "# df_msc.to_csv('data/data file 2/data_1_msc2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative Scatter Correction (MSC) function\n",
    "# def msc(input_data):\n",
    "#     # Mean center the data\n",
    "#     mean_spectrum = np.mean(input_data, axis=0)\n",
    "#     input_data_centered = input_data - mean_spectrum\n",
    "\n",
    "#     # Perform MSC\n",
    "#     reference = np.mean(input_data, axis=0)\n",
    "#     msc_data = np.zeros_like(input_data)\n",
    "\n",
    "#     for i in range(input_data.shape[0]):\n",
    "#         fit = np.polyfit(reference, input_data_centered[i, :], 1, full=True)\n",
    "#         msc_data[i, :] = (input_data_centered[i, :] - fit[0][1]) / fit[0][0]\n",
    "    \n",
    "#     return msc_data\n",
    "\n",
    "# # Extract the spectral data from the dataframe\n",
    "# spectral_data = df_0_selected_regions.iloc[:, 2:].values\n",
    "\n",
    "# # Apply MSC\n",
    "# msc_corrected_data = msc(spectral_data)\n",
    "\n",
    "# # Create a new dataframe with the MSC corrected data\n",
    "# msc_df = pd.DataFrame(msc_corrected_data, columns=df_0_selected_regions.columns[2:])\n",
    "# msc_df.insert(0, 'prov_char', df_0_selected_regions['prov_char'])\n",
    "# msc_df.insert(0, 'thnoth_name', df_0_selected_regions['thnoth_name'])\n",
    "\n",
    "# # Save the MSC corrected data to a new CSV file\n",
    "# msc_corrected_file_path = 'data/data file 2/data_1_msc_corrected.csv'\n",
    "# msc_df.to_csv(msc_corrected_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Evaluation (40-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'thnoth_name'\n",
    "\n",
    "# Ensure columns_to_focus are correctly identified\n",
    "numeric_cols_df_0 = df_0_selected_regions.select_dtypes(include=[np.number]).columns.tolist()\n",
    "columns_to_focus = numeric_cols_df_0  # Ensure columns are correctly selected\n",
    "\n",
    "# Classification and evaluation function using 40-fold CV\n",
    "def classify_and_evaluate(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "\n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "\n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=40)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Cross-Validation Accuracy: {np.mean(scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate each preprocessing method\n",
    "print(\"Evaluation for No Preprocessing:\")\n",
    "classify_and_evaluate(df_0_selected_regions, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for Baseline Correction:\")\n",
    "df_baseline_corrected_v0z = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "classify_and_evaluate(df_baseline_corrected_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for Smoothing:\")\n",
    "df_smoothed_v0z = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "classify_and_evaluate(df_smoothed_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for Normalization:\")\n",
    "df_normalized_v0z = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "classify_and_evaluate(df_normalized_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for 1-Derivative Spectroscopy:\")\n",
    "data_1_der_combined_v0z = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "classify_and_evaluate(data_1_der_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for 2-Derivative Spectroscopy:\")\n",
    "data_2_der_combined_v0z = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "classify_and_evaluate(data_2_der_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for 1-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0z = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for 2-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0z = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for SNV:\")\n",
    "df_snv_v0z = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "classify_and_evaluate(df_snv_v0z, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for RNV:\")\n",
    "df_rnv_v0z = pd.read_csv('data/data file 2/data_1_rnv.csv')\n",
    "classify_and_evaluate(df_rnv_v0z, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for MSC:\")\n",
    "df_msc_v0z = pd.read_csv('data/data file 2/data_1_msc.csv')\n",
    "classify_and_evaluate(df_msc_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Evaluation (40-fold) -with extra detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'thnoth_name'\n",
    "\n",
    "# Ensure columns_to_focus are correctly identified\n",
    "numeric_cols_df_0 = df_0_selected_regions.select_dtypes(include=[np.number]).columns.tolist()\n",
    "columns_to_focus = numeric_cols_df_0  # Ensure columns are correctly selected\n",
    "\n",
    "# Classification and evaluation function using 40-fold CV with detailed metrics\n",
    "def classify_and_evaluate(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    import numpy as np\n",
    "\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "\n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "\n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Initialize Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=40)\n",
    "\n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    conf_matrices = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average=None))\n",
    "        recalls.append(recall_score(y_test, y_pred, average=None))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average=None))\n",
    "        conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Calculate mean scores\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    mean_recall = np.mean(recalls, axis=0)\n",
    "    mean_f1 = np.mean(f1_scores, axis=0)\n",
    "    mean_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Cross-Validation Accuracy: {mean_accuracy}')\n",
    "    print(f'Precision per class: {mean_precision}')\n",
    "    print(f'Recall per class: {mean_recall}')\n",
    "    print(f'F1-score per class: {mean_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each preprocessing method\n",
    "print(\"Evaluation for No Preprocessing:\")\n",
    "classify_and_evaluate(df_0_selected_regions, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for Baseline Correction:\")\n",
    "df_baseline_corrected_v0y = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "classify_and_evaluate(df_baseline_corrected_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for Smoothing:\")\n",
    "df_smoothed_v0y = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "classify_and_evaluate(df_smoothed_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for Normalization:\")\n",
    "df_normalized_v0y = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "classify_and_evaluate(df_normalized_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 1-Derivative Spectroscopy:\")\n",
    "df_derivative_v0y = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "classify_and_evaluate(df_derivative_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 2-Derivative Spectroscopy:\")\n",
    "data_2_der_combined_v0y = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "classify_and_evaluate(data_2_der_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 1-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 2-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0y, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation for SNV:\")\n",
    "df_snv_v0y = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "classify_and_evaluate(df_snv_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for RNV:\")\n",
    "df_rnv_v0y = pd.read_csv('data/data file 2/data_1_rnv.csv')\n",
    "classify_and_evaluate(df_rnv_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for MSC:\")\n",
    "df_msc_v0y = pd.read_csv('data/data file 2/data_1_msc.csv')\n",
    "classify_and_evaluate(df_msc_v0y, columns_to_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Evaluation using LOGO-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    all_y_test = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "    # Calculate overall metrics\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    precision = precision_score(all_y_test, all_y_pred, average=None)\n",
    "    recall = recall_score(all_y_test, all_y_pred, average=None)\n",
    "    f1 = f1_score(all_y_test, all_y_pred, average=None)\n",
    "    conf_matrix = confusion_matrix(all_y_test, all_y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Mean Accuracy: {mean_accuracy}')\n",
    "    print(f'Precision per class: {precision}')\n",
    "    print(f'Recall per class: {recall}')\n",
    "    print(f'F1-score per class: {f1}')\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each preprocessing method using LOGO-CV with detailed metrics\n",
    "print(\"LOGO-CV Evaluation for No Preprocessing:\")\n",
    "conf_matrix_no_preprocessing_v0x = classify_and_evaluate_logo_cv_detailed(df_0_selected_regions, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for Baseline Correction:\")\n",
    "df_baseline_corrected_v0x = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "conf_matrix_baseline_v0x = classify_and_evaluate_logo_cv_detailed(df_baseline_corrected_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for Smoothing:\")\n",
    "df_smoothed_v0x = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "conf_matrix_smoothing_v0x = classify_and_evaluate_logo_cv_detailed(df_smoothed_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for Normalization:\")\n",
    "df_normalized_v0x = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "conf_matrix_normalization_v0x = classify_and_evaluate_logo_cv_detailed(df_normalized_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "df_1_derivative_v0x = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "conf_matrix_1_derivative_v0x = classify_and_evaluate_logo_cv_detailed(df_1_derivative_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 2-Derivative Spectroscopy:\")\n",
    "df_2_derivative_v0x = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "conf_matrix_2_derivative_v0x = classify_and_evaluate_logo_cv_detailed(df_2_derivative_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-SG-Derivative Spectroscopy:\")\n",
    "df_1_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "conf_matrix_1_sg_v0x = classify_and_evaluate_logo_cv_detailed(df_1_der_savgol_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 2-SG-Derivative Spectroscopy:\")\n",
    "df_2_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "conf_matrix_2_sg_v0x = classify_and_evaluate_logo_cv_detailed(df_2_der_savgol_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for SNV:\")\n",
    "df_snv_v0x = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "conf_matrix_snv_v0x = classify_and_evaluate_logo_cv_detailed(df_snv_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for RNV:\")\n",
    "df_rnv_v0x = pd.read_csv('data/data file 2/data_1_rnv.csv')\n",
    "conf_matrix_rnv_v0x = classify_and_evaluate_logo_cv_detailed(df_rnv_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for MSC:\")\n",
    "df_msc_v0x = pd.read_csv('data/data file 2/data_1_msc.csv')\n",
    "conf_matrix_msc_v0x = classify_and_evaluate_logo_cv_detailed(df_msc_v0x, columns_to_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix in a tabular format\n",
    "def display_confusion_matrix(conf_matrix, class_labels):\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "    print(df_cm)\n",
    "\n",
    "# Ensure LabelEncoder is defined and class labels are set\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the target variable and fit LabelEncoder\n",
    "target = 'thnoth_name'\n",
    "le = LabelEncoder()\n",
    "le.fit(df_0_selected_regions[target])\n",
    "class_labels = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrices for each preprocessing method\n",
    "print(\"Confusion Matrix for No Preprocessing:\")\n",
    "display_confusion_matrix(conf_matrix_no_preprocessing_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Baseline Correction:\")\n",
    "display_confusion_matrix(conf_matrix_baseline_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Smoothing:\")\n",
    "display_confusion_matrix(conf_matrix_smoothing_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Normalization:\")\n",
    "display_confusion_matrix(conf_matrix_normalization_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_1_derivative_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_2_derivative_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_1_sg_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_2_sg_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for SNV:\")\n",
    "display_confusion_matrix(conf_matrix_snv_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for RNV:\")\n",
    "display_confusion_matrix(conf_matrix_rnv_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for MSC:\")\n",
    "display_confusion_matrix(conf_matrix_msc_v0x, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_selected_regions = pd.read_csv('data/data file 2/data_1.csv')\n",
    "df_baseline_corrected = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "df_smoothed = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "df_normalized = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "df_1st_derivative = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "df_2nd_derivative = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "df_1_der_savgol = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "df_2_der_savgol = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "df_snv = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "df_rnv = pd.read_csv('data/data file 2/data_1_rnv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-Step Implementation for RandomForest Classifier with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Smoothed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smoothed dataset\n",
    "df_smoothed_v0w = pd.read_csv('data/data file 2/data_1_smoothed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Target Variable and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target_v0w variable and feature columns\n",
    "target_v0w = 'thnoth_name'\n",
    "features_v0w = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0w]\n",
    "y = df_smoothed_v0w[target_v0w]\n",
    "groups = df_smoothed_v0w['prov_char']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest Classification and Evaluation with LOGO-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the RandomForest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Calculate and store test accuracies\n",
    "    accuracies.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_all.extend(y_test)\n",
    "    y_pred_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate average accuracies\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {avg_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_rf_logo = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV RandomForest Model Classification Report\")\n",
    "print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_rf_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Different Classifiers on the Smoothed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "target_v0w = 'thnoth_name'\n",
    "features_v0w = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0w]\n",
    "y = df_smoothed_v0w[target_v0w]\n",
    "groups = df_smoothed_v0w['prov_char']\n",
    "\n",
    "# Encode the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def classify_and_evaluate_logo_cv(model, X, y, groups, class_labels):\n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    accuracies = []\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "\n",
    "    # Perform LOGO-CV\n",
    "    for train_index, test_index in logo.split(X, y, groups):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the test samples\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate and store test accuracies\n",
    "        accuracies.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "        # Store the prediction and actual value\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_test_pred)\n",
    "\n",
    "    # Calculate average accuracies\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "    print(f'Leave-One-Group-Out CV - Average Test Accuracy: {avg_accuracy}')\n",
    "\n",
    "    # Generate the classification report for the overall test predictions\n",
    "    report_logo = classification_report(y_true_all, y_pred_all, target_names=class_labels, output_dict=True)\n",
    "    print(f\"Leave-One-Group-Out CV {model.__class__.__name__} Classification Report\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=class_labels))\n",
    "\n",
    "    # Print the confusion matrix in text format\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_df)\n",
    "\n",
    "    # Print the detailed results\n",
    "    for class_name, metrics in report_logo.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{class_name}: {metrics}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement and Evaluate Each Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "target_v0w = 'thnoth_name'\n",
    "features_v0w = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0w]\n",
    "y = df_smoothed_v0w[target_v0w]\n",
    "groups = df_smoothed_v0w['prov_char']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the SVM classifier with different kernel\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate and store test accuracies\n",
    "    accuracies.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_all.extend(y_test)\n",
    "    y_pred_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate average accuracies\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {avg_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_svm_logo = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV SVM Model Classification Report\")\n",
    "print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_svm_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n",
    "\n",
    "# Calculate the overall accuracy from the classification report\n",
    "overall_accuracy_report = report_svm_logo['accuracy']\n",
    "print(f'Overall Accuracy from Classification Report: {overall_accuracy_report}')\n",
    "\n",
    "# Compare the accuracies\n",
    "if np.isclose(avg_accuracy, overall_accuracy_report):\n",
    "    print(\"The average test accuracy and overall accuracy from the classification report match.\")\n",
    "else:\n",
    "    print(\"There is a discrepancy between the average test accuracy and overall accuracy from the classification report.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable and feature columns\n",
    "target_v0w = 'thnoth_name'\n",
    "features_v0w = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0w]\n",
    "y = df_smoothed_v0w[target_v0w]\n",
    "groups = df_smoothed_v0w['prov_char']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_svm2_all = []\n",
    "y_pred_svm2_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_svm2_all.extend(y_test)\n",
    "    y_pred_svm2_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_svm2_all, y_pred_svm2_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_svm1_logo = classification_report(y_true_svm2_all, y_pred_svm2_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV SVM Model Classification Report\")\n",
    "print(classification_report(y_true_svm2_all, y_pred_svm2_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_svm2_all, y_pred_svm2_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_svm1_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest (RF) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_rf2_all = []\n",
    "y_pred_rf2_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_rf2_all.extend(y_test)\n",
    "    y_pred_rf2_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_rf2_all, y_pred_rf2_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_rf_logo = classification_report(y_true_rf2_all, y_pred_rf2_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "print(classification_report(y_true_rf2_all, y_pred_rf2_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_rf2_all, y_pred_rf2_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_rf_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees (ET) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the smoothed dataset\n",
    "df_smoothed_v0w = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "target_v0u = 'thnoth_name'\n",
    "features_v0u = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0u]\n",
    "y = df_smoothed_v0w[target_v0u]\n",
    "groups = df_smoothed_v0w['prov_char']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the Extra Trees classifier\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_et_all = []\n",
    "y_pred_et_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    et.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = et.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_et_all.extend(y_test)\n",
    "    y_pred_et_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_et_all, y_pred_et_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_et_logo = classification_report(y_true_et_all, y_pred_et_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Extra Trees Model Classification Report\")\n",
    "print(classification_report(y_true_et_all, y_pred_et_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_et_all, y_pred_et_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_et_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "target_v0u = 'thnoth_name'\n",
    "features_v0u = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0u]\n",
    "y = df_smoothed_v0w[target_v0u]\n",
    "groups = df_smoothed_v0w['prov_char']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_knn_all = []\n",
    "y_pred_knn_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_knn_all.extend(y_test)\n",
    "    y_pred_knn_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_knn_all, y_pred_knn_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_knn_logo = classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV kNN Model Classification Report\")\n",
    "print(classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_knn_all, y_pred_knn_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_knn_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier (GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "model_gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_gbc = []\n",
    "y_true_all_gbc = []\n",
    "y_pred_all_gbc = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_gbc.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_gbc.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_gbc.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_gbc.extend(y_test)\n",
    "    y_pred_all_gbc.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_gbc = accuracy_score(y_true_all_gbc, y_pred_all_gbc)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_gbc}')\n",
    "print(\"Leave-One-Group-Out CV GBC Model Classification Report\")\n",
    "report_gbc_logo = classification_report(y_true_all_gbc, y_pred_all_gbc, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_gbc, y_pred_all_gbc, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_gbc = confusion_matrix(y_true_all_gbc, y_pred_all_gbc)\n",
    "df_cm_gbc = pd.DataFrame(cm_logo_gbc, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_gbc)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_gbc_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM (LGBM) classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LightGBM Classifier\n",
    "model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lgbm = []\n",
    "y_true_all_lgbm = []\n",
    "y_pred_all_lgbm = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lgbm.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lgbm.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_lgbm.extend(y_test)\n",
    "    y_pred_all_lgbm.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_lgbm = accuracy_score(y_true_all_lgbm, y_pred_all_lgbm)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_lgbm}')\n",
    "print(\"Leave-One-Group-Out CV LGBM Model Classification Report\")\n",
    "report_lgbm_logo = classification_report(y_true_all_lgbm, y_pred_all_lgbm, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_lgbm, y_pred_all_lgbm, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_lgbm = confusion_matrix(y_true_all_lgbm, y_pred_all_lgbm)\n",
    "df_cm_lgbm = pd.DataFrame(cm_logo_lgbm, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_lgbm)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_lgbm_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis (LDA) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LDA Classifier\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lda = []\n",
    "y_true_all_lda = []\n",
    "y_pred_all_lda = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lda.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lda.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_lda.extend(y_test)\n",
    "    y_pred_all_lda.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_lda = accuracy_score(y_true_all_lda, y_pred_all_lda)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_lda}')\n",
    "print(\"Leave-One-Group-Out CV LDA Model Classification Report\")\n",
    "report_lda_logo = classification_report(y_true_all_lda, y_pred_all_lda, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_lda, y_pred_all_lda, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_lda = confusion_matrix(y_true_all_lda, y_pred_all_lda)\n",
    "df_cm_lda = pd.DataFrame(cm_logo_lda, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_lda)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_lda_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LDA Classifier\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lda = []\n",
    "y_true_all_ldar = []\n",
    "y_pred_all_ldar = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lda.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lda.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_ldar.extend(y_test)\n",
    "    y_pred_all_ldar.extend(y_test_pred)\n",
    "\n",
    "# Reverse the predicted classes\n",
    "y_pred_all_ldar_reversed = [1 - y for y in y_pred_all_ldar]\n",
    "\n",
    "# Calculate the overall accuracy for the reversed predictions\n",
    "overall_accuracy_lda_reversed = accuracy_score(y_true_all_ldar, y_pred_all_ldar_reversed)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy (Reversed Classes): {overall_accuracy_lda_reversed}')\n",
    "print(\"Leave-One-Group-Out CV LDA Model Classification Report (Reversed Classes)\")\n",
    "report_lda_logo_reversed = classification_report(y_true_all_ldar, y_pred_all_ldar_reversed, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_ldar, y_pred_all_ldar_reversed, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix for the reversed predictions\n",
    "cm_logo_lda_reversed = confusion_matrix(y_true_all_ldar, y_pred_all_ldar_reversed)\n",
    "df_cm_lda_reversed = pd.DataFrame(cm_logo_lda_reversed, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix (Reversed Classes):\")\n",
    "print(df_cm_lda_reversed)\n",
    "\n",
    "# Display the detailed results for the reversed predictions\n",
    "for class_name, metrics in report_lda_logo_reversed.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize Logistic Regression model with a different solver\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=10000, solver='liblinear')\n",
    "\n",
    "# Standardize the data (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "test_accuracies_logreg = []\n",
    "y_true_all_logreg = []\n",
    "y_pred_all_logreg = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled, y, groups):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = logreg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store test accuracies\n",
    "    test_accuracies_logreg.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_all_logreg.extend(y_test)\n",
    "    y_pred_all_logreg.extend(y_test_pred)\n",
    "\n",
    "# Flip the predictions\n",
    "y_pred_lg_flipped = ['Non-Thai' if pred == 'Thai' else 'Thai' for pred in y_pred_all_logreg]\n",
    "\n",
    "# Generate the classification report for the flipped predictions\n",
    "report_logreg_flipped = classification_report(y_true_all_logreg, y_pred_lg_flipped, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Logistic Regression Model (Flipped) Classification Report\")\n",
    "print(classification_report(y_true_all_logreg, y_pred_lg_flipped, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix for the flipped predictions\n",
    "cm_logreg_flipped = confusion_matrix(y_true_all_logreg, y_pred_lg_flipped)\n",
    "df_cm_logreg_flipped = pd.DataFrame(cm_logreg_flipped, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix (Flipped):\")\n",
    "print(df_cm_logreg_flipped)\n",
    "\n",
    "# Display the detailed results for the flipped predictions\n",
    "for class_name, metrics in report_logreg_flipped.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the true labels and predictions for each classifier stored in the following variables:\n",
    "# y_true_rf, y_pred_rf\n",
    "# y_true_svm, y_pred_svm\n",
    "# y_true_et, y_pred_et\n",
    "# y_true_knn, y_pred_knn\n",
    "# y_true_gbc, y_pred_gbc\n",
    "# y_true_lgbm, y_pred_lgbm\n",
    "# y_true_lda, y_pred_lda\n",
    "# y_true_logreg, y_pred_logreg\n",
    "\n",
    "# y_true_rf2_all, y_pred_rf2_all\n",
    "# y_true_svm2_all,  y_pred_svm2_all\n",
    "# y_true_et_all, y_pred_et_all\n",
    "# y_true_knn_all, y_pred_knn_all\n",
    "# y_true_all_gbc, y_pred_all_gbc\n",
    "# y_true_all_lgbm, y_pred_all_lgbm\n",
    "# y_true_all_ldar, y_pred_all_ldar_reversed\n",
    "# y_true_all_logreg, y_pred_lg_flipped\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = le.classes_\n",
    "\n",
    "# Function to display confusion matrix\n",
    "def display_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Display confusion matrices for each classifier\n",
    "display_confusion_matrix(y_true_rf2_all, y_pred_rf2_all, 'Random Forest Confusion Matrix')\n",
    "display_confusion_matrix(y_true_svm2_all,  y_pred_svm2_all, 'SVM Confusion Matrix')\n",
    "display_confusion_matrix(y_true_et_all, y_pred_et_all, 'Extra Trees Confusion Matrix')\n",
    "display_confusion_matrix(y_true_knn_all, y_pred_knn_all, 'kNN Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_gbc, y_pred_all_gbc, 'Gradient Boosting Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_lgbm, y_pred_all_lgbm, 'LightGBM Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_ldar, y_pred_all_ldar_reversed, 'LDA Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_logreg, y_pred_lg_flipped, 'Logistic Regression Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Confusion Matrices as Text Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix as a text table\n",
    "def display_confusion_matrix_text(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "    print(title)\n",
    "    print(df_cm)\n",
    "    print()\n",
    "\n",
    "# Display confusion matrices for each classifier as text tables\n",
    "display_confusion_matrix_text(y_true_rf2_all, y_pred_rf2_all, 'Random Forest Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_svm2_all,  y_pred_svm2_all, 'SVM Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_et_all, y_pred_et_all, 'Extra Trees Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_knn_all, y_pred_knn_all, 'kNN Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_gbc, y_pred_all_gbc, 'Gradient Boosting Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_lgbm, y_pred_all_lgbm, 'LightGBM Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_ldar, y_pred_all_ldar_reversed, 'LDA Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_logreg, y_pred_lg_flipped, 'Logistic Regression Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have these classification reports stored\n",
    "# classification_report_rf = ...\n",
    "# classification_report_svm = ...\n",
    "# classification_report_et = ...\n",
    "# classification_report_knn = ...\n",
    "# classification_report_gbc = ...\n",
    "# classification_report_lgbm = ...\n",
    "# classification_report_lda = ...\n",
    "# classification_report_logreg = ...\n",
    "\n",
    "# Function to display classification report\n",
    "def display_classification_report(report, model_name):\n",
    "    print(f\"Classification Report for {model_name}\")\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {label}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{label}: {metrics}\")\n",
    "        print()\n",
    "\n",
    "# Call the function for each classifier\n",
    "display_classification_report(report_rf_logo, \"Random Forest\")\n",
    "display_classification_report(report_svm1_logo, \"SVM\")\n",
    "display_classification_report(report_et_logo, \"Extra Trees\")\n",
    "display_classification_report(report_knn_logo, \"k-Nearest Neighbors\")\n",
    "display_classification_report(report_gbc_logo, \"Gradient Boosting Classifier\")\n",
    "display_classification_report(report_lgbm_logo, \"LightGBM\")\n",
    "display_classification_report(report_lda_logo_reversed, \"Linear Discriminant Analysis\")\n",
    "display_classification_report(report_logreg_flipped, \"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIO Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "target_v0u = 'thnoth_name'\n",
    "features_v0u = df_smoothed_v0w.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_smoothed_v0w[features_v0u]\n",
    "y = df_smoothed_v0w[target_v0u]\n",
    "groups = df_smoothed_v0w['prov_char']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Function to evaluate a classifier using LOGO-CV\n",
    "def evaluate_classifier(clf, classifier_name):\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "\n",
    "    for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "        # Fit the model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the test samples\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "\n",
    "        # Store the prediction and actual value\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_test_pred)\n",
    "\n",
    "    # Calculate the overall accuracy\n",
    "    overall_accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "    print(f'Leave-One-Group-Out CV - Overall Test Accuracy for {classifier_name}: {overall_accuracy}')\n",
    "\n",
    "    # Generate the classification report for the overall test predictions\n",
    "    report = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "    print(f\"Leave-One-Group-Out CV {classifier_name} Model Classification Report\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "\n",
    "    # Print the confusion matrix in text format\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "    print(f\"Confusion Matrix for {classifier_name}:\")\n",
    "    print(conf_matrix_df)\n",
    "\n",
    "    # Print the detailed results\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{class_name}: {metrics}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Evaluate each classifier\n",
    "evaluate_classifier(rf, \"Random Forest\")\n",
    "evaluate_classifier(svm, \"SVM\")\n",
    "evaluate_classifier(et, \"Extra Trees\")\n",
    "evaluate_classifier(knn, \"k-Nearest Neighbors\")\n",
    "evaluate_classifier(gbc, \"Gradient Boosting Classifier\")\n",
    "evaluate_classifier(lda, \"Linear Discriminant Analysis\")\n",
    "evaluate_classifier(logreg, \"Logistic Regression\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
