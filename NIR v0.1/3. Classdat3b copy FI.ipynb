{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_0 = pd.read_csv(r\"C:\\Users\\pingk\\Downloads\\fadhli nitip\\asik_NIR_DIST_3b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prov_char country_char           wavenumber     11544     11540     11536  \\\n",
      "0       KAX           ID  ID-KAX-088-2401-001  0.290252  0.290122  0.290044   \n",
      "1       KBX           ID  ID-KBX-068-2306-003  0.522845  0.522798  0.522826   \n",
      "2       BBX           ID  ID-BBX-095-2401-004 -0.144108 -0.144008 -0.143893   \n",
      "3       SUX           ID  ID-SUX-074-2311-001  0.333905  0.333777  0.333785   \n",
      "4       SUX           ID  ID-SUX-073-2311-001  1.522433  1.521460  1.521133   \n",
      "\n",
      "      11532     11528     11524     11520  ...      3964      3960      3956  \\\n",
      "0  0.290029  0.290042  0.289978  0.289851  ...  3.558086  3.542757  3.530849   \n",
      "1  0.522669  0.522414  0.522217  0.522070  ...  3.680422  3.655416  3.629388   \n",
      "2 -0.143777 -0.143686 -0.143667 -0.143678  ...  3.650478  3.623180  3.614590   \n",
      "3  0.333700  0.333522  0.333453  0.333446  ...  3.601331  3.566453  3.539593   \n",
      "4  1.521072  1.521494  1.522300  1.521840  ...  4.103365  4.125110  4.113971   \n",
      "\n",
      "       3952  tgp_name  dgp_name  fgp_name  country_name  thnoth_name  \\\n",
      "0  3.501222   Group 3   Group 2   Group 4     Indonesia     Non-Thai   \n",
      "1  3.606223   Group 3   Group 2   Group 4     Indonesia     Non-Thai   \n",
      "2  3.581875   Group 3   Group 2   Group 3     Indonesia     Non-Thai   \n",
      "3  3.512285   Group 3   Group 2   Group 3     Indonesia     Non-Thai   \n",
      "4  4.055192   Group 3   Group 2   Group 3     Indonesia     Non-Thai   \n",
      "\n",
      "   thnoth_name_encoded  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n",
      "\n",
      "[5 rows x 1908 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_0.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regions of interest\n",
    "regions_of_interest = [\n",
    "    (4641, 4681), (4867, 5510), (5657, 5826), (7057, 7097),\n",
    "    (7169, 7209), (8238, 8278)\n",
    "]\n",
    "\n",
    "# Extract columns corresponding to the regions of interest\n",
    "columns_to_focus = []\n",
    "for start, end in regions_of_interest:\n",
    "    columns_to_focus.extend([col for col in df_0.columns[4:-7] if start <= float(col) <= end])\n",
    "\n",
    "# Create a new DataFrame with the selected regions\n",
    "df_0_selected_regions = df_0[columns_to_focus]\n",
    "\n",
    "# Combine the selected regions with the target column and other relevant columns\n",
    "df_0_selected_regions = pd.concat([df_0[['thnoth_name', 'prov_char']], df_0_selected_regions], axis=1)\n",
    "\n",
    "# Save the DataFrame for further processing\n",
    "#df_0_selected_regions.to_csv('data/data file 2b/data_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thnoth_name</th>\n",
       "      <th>prov_char</th>\n",
       "      <th>4680</th>\n",
       "      <th>4676</th>\n",
       "      <th>4672</th>\n",
       "      <th>4668</th>\n",
       "      <th>4664</th>\n",
       "      <th>4660</th>\n",
       "      <th>4656</th>\n",
       "      <th>4652</th>\n",
       "      <th>...</th>\n",
       "      <th>8276</th>\n",
       "      <th>8272</th>\n",
       "      <th>8268</th>\n",
       "      <th>8264</th>\n",
       "      <th>8260</th>\n",
       "      <th>8256</th>\n",
       "      <th>8252</th>\n",
       "      <th>8248</th>\n",
       "      <th>8244</th>\n",
       "      <th>8240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>KAX</td>\n",
       "      <td>1.145221</td>\n",
       "      <td>1.161998</td>\n",
       "      <td>1.183733</td>\n",
       "      <td>1.206279</td>\n",
       "      <td>1.221476</td>\n",
       "      <td>1.219369</td>\n",
       "      <td>1.195433</td>\n",
       "      <td>1.155057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693094</td>\n",
       "      <td>0.696532</td>\n",
       "      <td>0.699208</td>\n",
       "      <td>0.701041</td>\n",
       "      <td>0.702028</td>\n",
       "      <td>0.702149</td>\n",
       "      <td>0.701310</td>\n",
       "      <td>0.699461</td>\n",
       "      <td>0.696617</td>\n",
       "      <td>0.692720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>KBX</td>\n",
       "      <td>1.100158</td>\n",
       "      <td>1.117663</td>\n",
       "      <td>1.140348</td>\n",
       "      <td>1.163641</td>\n",
       "      <td>1.178847</td>\n",
       "      <td>1.175626</td>\n",
       "      <td>1.149462</td>\n",
       "      <td>1.106238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827193</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.833110</td>\n",
       "      <td>0.834886</td>\n",
       "      <td>0.835800</td>\n",
       "      <td>0.835858</td>\n",
       "      <td>0.835008</td>\n",
       "      <td>0.833129</td>\n",
       "      <td>0.830211</td>\n",
       "      <td>0.826278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>BBX</td>\n",
       "      <td>0.873460</td>\n",
       "      <td>0.891096</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.937998</td>\n",
       "      <td>0.954190</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>0.926066</td>\n",
       "      <td>0.882441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370219</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.376443</td>\n",
       "      <td>0.378311</td>\n",
       "      <td>0.379332</td>\n",
       "      <td>0.379466</td>\n",
       "      <td>0.378665</td>\n",
       "      <td>0.376875</td>\n",
       "      <td>0.374042</td>\n",
       "      <td>0.370139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>SUX</td>\n",
       "      <td>1.014767</td>\n",
       "      <td>1.031323</td>\n",
       "      <td>1.052854</td>\n",
       "      <td>1.075045</td>\n",
       "      <td>1.089551</td>\n",
       "      <td>1.086283</td>\n",
       "      <td>1.060706</td>\n",
       "      <td>1.018413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694977</td>\n",
       "      <td>0.698438</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.702996</td>\n",
       "      <td>0.703988</td>\n",
       "      <td>0.704090</td>\n",
       "      <td>0.703278</td>\n",
       "      <td>0.701477</td>\n",
       "      <td>0.698633</td>\n",
       "      <td>0.694729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>SUX</td>\n",
       "      <td>1.520511</td>\n",
       "      <td>1.536409</td>\n",
       "      <td>1.557498</td>\n",
       "      <td>1.579159</td>\n",
       "      <td>1.592749</td>\n",
       "      <td>1.588327</td>\n",
       "      <td>1.561828</td>\n",
       "      <td>1.519022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606612</td>\n",
       "      <td>1.609559</td>\n",
       "      <td>1.611674</td>\n",
       "      <td>1.613343</td>\n",
       "      <td>1.614402</td>\n",
       "      <td>1.614270</td>\n",
       "      <td>1.612957</td>\n",
       "      <td>1.610735</td>\n",
       "      <td>1.607516</td>\n",
       "      <td>1.603303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  thnoth_name prov_char      4680      4676      4672      4668      4664  \\\n",
       "0    Non-Thai       KAX  1.145221  1.161998  1.183733  1.206279  1.221476   \n",
       "1    Non-Thai       KBX  1.100158  1.117663  1.140348  1.163641  1.178847   \n",
       "2    Non-Thai       BBX  0.873460  0.891096  0.914072  0.937998  0.954190   \n",
       "3    Non-Thai       SUX  1.014767  1.031323  1.052854  1.075045  1.089551   \n",
       "4    Non-Thai       SUX  1.520511  1.536409  1.557498  1.579159  1.592749   \n",
       "\n",
       "       4660      4656      4652  ...      8276      8272      8268      8264  \\\n",
       "0  1.219369  1.195433  1.155057  ...  0.693094  0.696532  0.699208  0.701041   \n",
       "1  1.175626  1.149462  1.106238  ...  0.827193  0.830521  0.833110  0.834886   \n",
       "2  0.951890  0.926066  0.882441  ...  0.370219  0.373736  0.376443  0.378311   \n",
       "3  1.086283  1.060706  1.018413  ...  0.694977  0.698438  0.701122  0.702996   \n",
       "4  1.588327  1.561828  1.519022  ...  1.606612  1.609559  1.611674  1.613343   \n",
       "\n",
       "       8260      8256      8252      8248      8244      8240  \n",
       "0  0.702028  0.702149  0.701310  0.699461  0.696617  0.692720  \n",
       "1  0.835800  0.835858  0.835008  0.833129  0.830211  0.826278  \n",
       "2  0.379332  0.379466  0.378665  0.376875  0.374042  0.370139  \n",
       "3  0.703988  0.704090  0.703278  0.701477  0.698633  0.694729  \n",
       "4  1.614402  1.614270  1.612957  1.610735  1.607516  1.603303  \n",
       "\n",
       "[5 rows x 245 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0_selected_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define the target variable\n",
    "target = 'thnoth_name'\n",
    "\n",
    "# Ensure columns_to_focus are correctly identified\n",
    "numeric_cols_df_0 = df_0_selected_regions.select_dtypes(include=[np.number]).columns.tolist()\n",
    "columns_to_focus = numeric_cols_df_0  # Ensure columns are correctly selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-Step Implementation for Classifiers Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smoothed dataset\n",
    "df_1dernp_v00 = pd.read_csv('data/data file 2/data_1_2_der.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Target Variable and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target_v00 variable and feature columns\n",
    "target_v00 = 'thnoth_name'\n",
    "features_v00 = df_1dernp_v00.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_1dernp_v00[features_v00]\n",
    "y = df_1dernp_v00[target_v00]\n",
    "groups = df_1dernp_v00['prov_char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-One-Group-Out CV - Overall Test Accuracy: 0.8351063829787234\n",
      "Leave-One-Group-Out CV SVM Model Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Thai       0.94      0.72      0.81       470\n",
      "        Thai       0.77      0.95      0.85       470\n",
      "\n",
      "    accuracy                           0.84       940\n",
      "   macro avg       0.85      0.84      0.83       940\n",
      "weighted avg       0.85      0.84      0.83       940\n",
      "\n",
      "Confusion Matrix:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       338   132\n",
      "Thai            23   447\n",
      "Class: Non-Thai\n",
      "precision: 0.9362880886426593\n",
      "recall: 0.7191489361702128\n",
      "f1-score: 0.8134777376654633\n",
      "support: 470.0\n",
      "\n",
      "Class: Thai\n",
      "precision: 0.772020725388601\n",
      "recall: 0.951063829787234\n",
      "f1-score: 0.8522402287893232\n",
      "support: 470.0\n",
      "\n",
      "accuracy: 0.8351063829787234\n",
      "\n",
      "Class: macro avg\n",
      "precision: 0.8541544070156302\n",
      "recall: 0.8351063829787234\n",
      "f1-score: 0.8328589832273932\n",
      "support: 940.0\n",
      "\n",
      "Class: weighted avg\n",
      "precision: 0.8541544070156301\n",
      "recall: 0.8351063829787234\n",
      "f1-score: 0.8328589832273933\n",
      "support: 940.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_svm = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_svm2_all = []\n",
    "y_pred_svm2_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled_svm, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled_svm[train_index], X_scaled_svm[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_svm2_all.extend(y_test)\n",
    "    y_pred_svm2_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_svm2_all, y_pred_svm2_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_svm1_logo = classification_report(y_true_svm2_all, y_pred_svm2_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV SVM Model Classification Report\")\n",
    "print(classification_report(y_true_svm2_all, y_pred_svm2_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_svm2_all, y_pred_svm2_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_svm1_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest (RF) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGO-CV Evaluation for 1-Derivative Spectroscopy:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['4680', '4676'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conf_matrix\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOGO-CV Evaluation for 1-Derivative Spectroscopy:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m conf_matrix_1_derivative_v03 \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_and_evaluate_logo_cv_detailed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_1dernp_v00\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_focus\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m, in \u001b[0;36mclassify_and_evaluate_logo_cv_detailed\u001b[1;34m(df, columns)\u001b[0m\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[target])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define features\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize the classifier\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pingk\\OneDrive - Chulalongkorn University\\Documents\\mekargit\\cpocluster\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\pingk\\OneDrive - Chulalongkorn University\\Documents\\mekargit\\cpocluster\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pingk\\OneDrive - Chulalongkorn University\\Documents\\mekargit\\cpocluster\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['4680', '4676'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and store results\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "    precision = precision_score(y_true_all, y_pred_all, average=None)\n",
    "    recall = recall_score(y_true_all, y_pred_all, average=None)\n",
    "    f1 = f1_score(y_true_all, y_pred_all, average=None)\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "    print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "    \n",
    "    # Print the confusion matrix in text format\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_df)\n",
    "    \n",
    "    # Print the detailed results\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{class_name}: {metrics}\")\n",
    "        print()\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "conf_matrix_1_derivative_v03 = classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    all_y_test = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "    # Calculate overall metrics\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    precision = precision_score(all_y_test, all_y_pred, average=None)\n",
    "    recall = recall_score(all_y_test, all_y_pred, average=None)\n",
    "    f1 = f1_score(all_y_test, all_y_pred, average=None)\n",
    "    conf_matrix = confusion_matrix(all_y_test, all_y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Mean Accuracy: {mean_accuracy}')\n",
    "    print(f'Precision per class: {precision}')\n",
    "    print(f'Recall per class: {recall}')\n",
    "    print(f'F1-score per class: {f1}')\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "conf_matrix_1_derivative_v03 = classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and store results\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = np.mean(accuracies)\n",
    "    precision = precision_score(y_true_all, y_pred_all, average=None)\n",
    "    recall = recall_score(y_true_all, y_pred_all, average=None)\n",
    "    f1 = f1_score(y_true_all, y_pred_all, average=None)\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "    print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "    \n",
    "    # Print the confusion matrix in text format\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_df)\n",
    "    \n",
    "    # Print the detailed results\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{class_name}: {metrics}\")\n",
    "        print()\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "conf_matrix_1_derivative_v03 = classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "y_true_rf3_all = []\n",
    "y_pred_rf3_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_rf3_all.extend(y_test)\n",
    "    y_pred_rf3_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = np.mean(accuracies) #accuracy_score(y_true_rf3_all, y_pred_rf3_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_rf_logo = classification_report(y_true_rf3_all, y_pred_rf3_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "print(classification_report(y_true_rf3_all, y_pred_rf3_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_rf3_all, y_pred_rf3_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_rf_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees (ET) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the Extra Trees classifier\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_et_all = []\n",
    "y_pred_et_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    et.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = et.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_et_all.extend(y_test)\n",
    "    y_pred_et_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_et_all, y_pred_et_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_et_logo = classification_report(y_true_et_all, y_pred_et_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Extra Trees Model Classification Report\")\n",
    "print(classification_report(y_true_et_all, y_pred_et_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_et_all, y_pred_et_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_et_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_knn_all = []\n",
    "y_pred_knn_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_knn_all.extend(y_test)\n",
    "    y_pred_knn_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_knn_all, y_pred_knn_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_knn_logo = classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV kNN Model Classification Report\")\n",
    "print(classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_knn_all, y_pred_knn_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_knn_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Standardize the features after SNV transformation\n",
    "scaler = StandardScaler()\n",
    "X_scaled_knn = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_knn_all = []\n",
    "y_pred_knn_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled_knn, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled_knn[train_index], X_scaled_knn[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_knn_all.extend(y_test)\n",
    "    y_pred_knn_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_knn_all, y_pred_knn_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_knn_logo = classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV kNN Model Classification Report\")\n",
    "print(classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_knn_all, y_pred_knn_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_knn_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier (GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "model_gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_gbc = []\n",
    "y_true_all_gbc = []\n",
    "y_pred_all_gbc = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_gbc.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_gbc.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_gbc.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_gbc.extend(y_test)\n",
    "    y_pred_all_gbc.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_gbc = accuracy_score(y_true_all_gbc, y_pred_all_gbc)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_gbc}')\n",
    "print(\"Leave-One-Group-Out CV GBC Model Classification Report\")\n",
    "report_gbc_logo = classification_report(y_true_all_gbc, y_pred_all_gbc, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_gbc, y_pred_all_gbc, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_gbc = confusion_matrix(y_true_all_gbc, y_pred_all_gbc)\n",
    "df_cm_gbc = pd.DataFrame(cm_logo_gbc, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_gbc)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_gbc_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM (LGBM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LightGBM Classifier\n",
    "model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lgbm = []\n",
    "y_true_all_lgbm = []\n",
    "y_pred_all_lgbm = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lgbm.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lgbm.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_lgbm.extend(y_test)\n",
    "    y_pred_all_lgbm.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_lgbm = accuracy_score(y_true_all_lgbm, y_pred_all_lgbm)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_lgbm}')\n",
    "print(\"Leave-One-Group-Out CV LGBM Model Classification Report\")\n",
    "report_lgbm_logo = classification_report(y_true_all_lgbm, y_pred_all_lgbm, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_lgbm, y_pred_all_lgbm, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_lgbm = confusion_matrix(y_true_all_lgbm, y_pred_all_lgbm)\n",
    "df_cm_lgbm = pd.DataFrame(cm_logo_lgbm, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_lgbm)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_lgbm_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis (LDA) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LDA Classifier\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lda = []\n",
    "y_true_all_ldar = []\n",
    "y_pred_all_ldar = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lda.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lda.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_ldar.extend(y_test)\n",
    "    y_pred_all_ldar.extend(y_test_pred)\n",
    "\n",
    "# Reverse the predicted classes\n",
    "y_pred_all_ldar_reversed = [1 - y for y in y_pred_all_ldar]\n",
    "\n",
    "# Calculate the overall accuracy for the reversed predictions\n",
    "overall_accuracy_lda_reversed = accuracy_score(y_true_all_ldar, y_pred_all_ldar_reversed)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy (Reversed Classes): {overall_accuracy_lda_reversed}')\n",
    "print(\"Leave-One-Group-Out CV LDA Model Classification Report (Reversed Classes)\")\n",
    "report_lda_logo_reversed = classification_report(y_true_all_ldar, y_pred_all_ldar_reversed, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_ldar, y_pred_all_ldar_reversed, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix for the reversed predictions\n",
    "cm_logo_lda_reversed = confusion_matrix(y_true_all_ldar, y_pred_all_ldar_reversed)\n",
    "df_cm_lda_reversed = pd.DataFrame(cm_logo_lda_reversed, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix (Reversed Classes):\")\n",
    "print(df_cm_lda_reversed)\n",
    "\n",
    "# Display the detailed results for the reversed predictions\n",
    "for class_name, metrics in report_lda_logo_reversed.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize Logistic Regression model with a different solver\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=10000, solver='liblinear')\n",
    "\n",
    "# Standardize the data (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "test_accuracies_logreg = []\n",
    "y_true_all_logreg = []\n",
    "y_pred_all_logreg = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled, y, groups):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = logreg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store test accuracies\n",
    "    test_accuracies_logreg.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_all_logreg.extend(y_test)\n",
    "    y_pred_all_logreg.extend(y_test_pred)\n",
    "\n",
    "# Flip the predictions\n",
    "y_pred_lg_flipped = ['Non-Thai' if pred == 'Thai' else 'Thai' for pred in y_pred_all_logreg]\n",
    "\n",
    "# Generate the classification report for the flipped predictions\n",
    "report_logreg_flipped = classification_report(y_true_all_logreg, y_pred_lg_flipped, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Logistic Regression Model (Flipped) Classification Report\")\n",
    "print(classification_report(y_true_all_logreg, y_pred_lg_flipped, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix for the flipped predictions\n",
    "cm_logreg_flipped = confusion_matrix(y_true_all_logreg, y_pred_lg_flipped)\n",
    "df_cm_logreg_flipped = pd.DataFrame(cm_logreg_flipped, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix (Flipped):\")\n",
    "print(df_cm_logreg_flipped)\n",
    "\n",
    "# Display the detailed results for the flipped predictions\n",
    "for class_name, metrics in report_logreg_flipped.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have these classification reports stored\n",
    "# classification_report_rf = ...\n",
    "# classification_report_svm = ...\n",
    "# classification_report_et = ...\n",
    "# classification_report_knn = ...\n",
    "# classification_report_gbc = ...\n",
    "# classification_report_lgbm = ...\n",
    "# classification_report_lda = ...\n",
    "# classification_report_logreg = ...\n",
    "\n",
    "# Function to display classification report\n",
    "def display_classification_report(report, model_name):\n",
    "    print(f\"Classification Report for {model_name}\")\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {label}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{label}: {metrics}\")\n",
    "        print()\n",
    "\n",
    "# Call the function for each classifier\n",
    "display_classification_report(report_rf_logo, \"Random Forest\")\n",
    "display_classification_report(report_svm1_logo, \"SVM\")\n",
    "display_classification_report(report_et_logo, \"Extra Trees\")\n",
    "display_classification_report(report_knn_logo, \"k-Nearest Neighbors\")\n",
    "display_classification_report(report_gbc_logo, \"Gradient Boosting Classifier\")\n",
    "display_classification_report(report_lgbm_logo, \"LightGBM\")\n",
    "display_classification_report(report_lda_logo_reversed, \"Linear Discriminant Analysis\")\n",
    "display_classification_report(report_logreg_flipped, \"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the true labels and predictions for each classifier stored in the following variables:\n",
    "# y_true_rf, y_pred_rf\n",
    "# y_true_svm, y_pred_svm\n",
    "# y_true_et, y_pred_et\n",
    "# y_true_knn, y_pred_knn\n",
    "# y_true_gbc, y_pred_gbc\n",
    "# y_true_lgbm, y_pred_lgbm\n",
    "# y_true_lda, y_pred_lda\n",
    "# y_true_logreg, y_pred_logreg\n",
    "\n",
    "# y_true_rf2_all, y_pred_rf2_all\n",
    "# y_true_svm2_all,  y_pred_svm2_all\n",
    "# y_true_et_all, y_pred_et_all\n",
    "# y_true_knn_all, y_pred_knn_all\n",
    "# y_true_all_gbc, y_pred_all_gbc\n",
    "# y_true_all_lgbm, y_pred_all_lgbm\n",
    "# y_true_all_ldar, y_pred_all_ldar_reversed\n",
    "# y_true_all_logreg, y_pred_lg_flipped\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = le.classes_\n",
    "\n",
    "# Function to display confusion matrix\n",
    "def display_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Display confusion matrices for each classifier\n",
    "display_confusion_matrix(y_true_rf3_all, y_pred_rf3_all, 'Random Forest Confusion Matrix')\n",
    "display_confusion_matrix(y_true_svm2_all,  y_pred_svm2_all, 'SVM Confusion Matrix')\n",
    "display_confusion_matrix(y_true_et_all, y_pred_et_all, 'Extra Trees Confusion Matrix')\n",
    "display_confusion_matrix(y_true_knn_all, y_pred_knn_all, 'kNN Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_gbc, y_pred_all_gbc, 'Gradient Boosting Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_lgbm, y_pred_all_lgbm, 'LightGBM Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_ldar, y_pred_all_ldar_reversed, 'LDA Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_logreg, y_pred_lg_flipped, 'Logistic Regression Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Confusion Matrices as Text Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix as a text table\n",
    "def display_confusion_matrix_text(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "    print(title)\n",
    "    print(df_cm)\n",
    "    print()\n",
    "\n",
    "# Display confusion matrices for each classifier as text tables\n",
    "display_confusion_matrix_text(y_true_rf3_all, y_pred_rf3_all, 'Random Forest Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_svm2_all,  y_pred_svm2_all, 'SVM Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_et_all, y_pred_et_all, 'Extra Trees Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_knn_all, y_pred_knn_all, 'kNN Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_gbc, y_pred_all_gbc, 'Gradient Boosting Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_lgbm, y_pred_all_lgbm, 'LightGBM Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_ldar, y_pred_all_ldar_reversed, 'LDA Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_logreg, y_pred_lg_flipped, 'Logistic Regression Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances\n",
    "rf_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "rf_importance_df = rf_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(rf_importance_df)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(rf_importance_df['Feature'][:50], rf_importance_df['Importance'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 50 Feature Importances from Random Forest')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances\n",
    "et_importances = et.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "et_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': et_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "et_importance_df = et_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(et_importance_df)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(et_importance_df['Feature'][:50], et_importance_df['Importance'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 50 Feature Importances from Extra Trees')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances\n",
    "gbc_importances = model_gbc.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "gbc_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': gbc_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "gbc_importance_df = gbc_importance_df\n",
    "\n",
    "# Sort by importance\n",
    "gbc_importance_df = gbc_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(gbc_importance_df)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(gbc_importance_df['Feature'][:50], gbc_importance_df['Importance'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 50 Feature Importances from Gradient Boosting Classifier')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances\n",
    "lgbm_importances = model_lgbm.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "lgbm_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': lgbm_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "lgbm_importance_df = lgbm_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(lgbm_importance_df)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(lgbm_importance_df['Feature'][:50], lgbm_importance_df['Importance'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 50 Feature Importances from LightGBM')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract LDA loadings\n",
    "lda_loadings = model_lda.scalings_\n",
    "\n",
    "# Create a DataFrame for LDA loadings\n",
    "lda_loadings_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Loading': lda_loadings.flatten()\n",
    "})\n",
    "\n",
    "# Sort by loading magnitude\n",
    "lda_loadings_df['abs_loading'] = lda_loadings_df['Loading'].abs()\n",
    "lda_loadings_df = lda_loadings_df.sort_values(by='abs_loading', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(lda_loadings_df)\n",
    "\n",
    "# Plot the LDA loadings\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(lda_loadings_df['Feature'][:50], lda_loadings_df['Loading'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Loading')\n",
    "plt.title('Top 50 LDA Loadings')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Logistic Regression coefficients\n",
    "logreg_coefs = logreg_model.coef_.flatten()\n",
    "\n",
    "# Create a DataFrame for Logistic Regression coefficients\n",
    "logreg_coefs_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': logreg_coefs\n",
    "})\n",
    "\n",
    "# Sort by coefficient magnitude\n",
    "logreg_coefs_df['abs_coef'] = logreg_coefs_df['Coefficient'].abs()\n",
    "logreg_coefs_df = logreg_coefs_df.sort_values(by='abs_coef', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(logreg_coefs_df)\n",
    "\n",
    "# Plot the Logistic Regression coefficients\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(logreg_coefs_df['Feature'][:50], logreg_coefs_df['Coefficient'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Top 50 Logistic Regression Coefficients')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_svm_all = []\n",
    "y_pred_svm_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_svm_all.extend(y_test)\n",
    "    y_pred_svm_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_svm_all, y_pred_svm_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_svm_logo = classification_report(y_true_svm_all, y_pred_svm_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV SVM Model Classification Report\")\n",
    "print(classification_report(y_true_svm_all, y_pred_svm_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_svm_all, y_pred_svm_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importances on the test set\n",
    "perm_importance = permutation_importance(svm, X_scaled, y_encoded, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create a DataFrame for permutation importances\n",
    "svm_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "svm_importance_df = svm_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(svm_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(svm_importance_df['Feature'][:50], svm_importance_df['Importance'][:50], color='blue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 50 Feature Importances from SVM (Permutation Importance)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
