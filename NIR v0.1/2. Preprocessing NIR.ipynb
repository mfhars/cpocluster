{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_0 = pd.read_csv(r\"C:\\Users\\pingk\\Downloads\\fadhli nitip\\asik_NIR_DIST_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regions of interest\n",
    "regions_of_interest = [\n",
    "    (4641, 4681), (4867, 5510), (5657, 5826), (7057, 7097),\n",
    "    (7169, 7209), (8238, 8278)\n",
    "]\n",
    "\n",
    "# Extract columns corresponding to the regions of interest\n",
    "columns_to_focus = []\n",
    "for start, end in regions_of_interest:\n",
    "    columns_to_focus.extend([col for col in df_0.columns[4:-2] if start <= float(col) <= end])\n",
    "\n",
    "# Create a new DataFrame with the selected regions\n",
    "df_0_selected_regions = df_0[columns_to_focus]\n",
    "\n",
    "# Combine the selected regions with the target column and other relevant columns\n",
    "df_0_selected_regions = pd.concat([df_0[['thnoth_name', 'prov_char']], df_0_selected_regions], axis=1)\n",
    "\n",
    "# Save the DataFrame for further processing\n",
    "df_0_selected_regions.to_csv('data/data file 2/data_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Function for baseline correction with dynamic window length\n",
    "def baseline_correction(spectrum, default_window_length=15, polyorder=3):\n",
    "    spectrum_length = len(spectrum)\n",
    "    if spectrum_length < default_window_length:\n",
    "        window_length = spectrum_length // 2 * 2 + 1  # Make window length odd and less than the size of the spectrum\n",
    "    else:\n",
    "        window_length = default_window_length\n",
    "    baseline = savgol_filter(spectrum, window_length, polyorder, mode='nearest')\n",
    "    corrected_spectrum = spectrum - baseline\n",
    "    return corrected_spectrum\n",
    "\n",
    "# Apply baseline correction\n",
    "df_baseline_corrected_v0 = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_baseline_corrected_v0[col] = baseline_correction(df_baseline_corrected_v0[col])\n",
    "\n",
    "# Save the baseline corrected data\n",
    "df_baseline_corrected_v0.to_csv('data/data file 2/data_1_bslcrct.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavGol Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Savitzky-Golay smoothing\n",
    "def savitzky_golay_smoothing(spectrum, default_window_length=11, polyorder=2):\n",
    "    window_length = min(default_window_length, len(spectrum) // 2 * 2 + 1)  # Make window length odd and less than or equal to the size of the spectrum\n",
    "    if window_length < 3:  # Ensure window length is at least 3\n",
    "        window_length = 3\n",
    "    return savgol_filter(spectrum, window_length, polyorder, mode='nearest')  # Set mode to 'nearest'\n",
    "\n",
    "# Apply smoothing\n",
    "df_smoothed_v0 = df_baseline_corrected_v0.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_smoothed_v0[col] = savitzky_golay_smoothing(df_smoothed_v0[col])\n",
    "\n",
    "# Save the smoothed data\n",
    "df_smoothed_v0.to_csv('data/data file 2/data_1_smoothed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for normalization (Min-Max scaling)\n",
    "def min_max_normalization(spectrum):\n",
    "    return (spectrum - np.min(spectrum)) / (np.max(spectrum) - np.min(spectrum))\n",
    "\n",
    "# Apply normalization\n",
    "df_normalized_v0 = df_smoothed_v0.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_normalized_v0[col] = min_max_normalization(df_normalized_v0[col])\n",
    "\n",
    "# Save the normalized data\n",
    "df_normalized_v0.to_csv('data/data file 2/data_1_normalized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatization (np.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first derivative using np.gradient\n",
    "data_spectrum = df_normalized_v0.iloc[:, 2:].values\n",
    "first_derivative_np = np.gradient(data_spectrum, axis=1)\n",
    "\n",
    "# Calculate the second derivative using np.gradient\n",
    "second_derivative_np = np.gradient(first_derivative_np, axis=1)\n",
    "\n",
    "# Convert the results back to DataFrame\n",
    "data_1_der_np = pd.DataFrame(first_derivative_np, columns=df_normalized_v0.columns[2:])\n",
    "data_2_der_np = pd.DataFrame(second_derivative_np, columns=df_normalized_v0.columns[2:])\n",
    "\n",
    "# Combine the first two columns from the original dataset with the np.gradient derivatives\n",
    "\n",
    "# Extract the first two columns\n",
    "first_two_columns = df_normalized_v0.iloc[:, :2]\n",
    "\n",
    "# Combine the first two columns with the derivatives\n",
    "data_1_der_combined = pd.concat([first_two_columns, data_1_der_np], axis=1)\n",
    "data_2_der_combined = pd.concat([first_two_columns, data_2_der_np], axis=1)\n",
    "\n",
    "# Export the combined data to CSV\n",
    "data_1_der_combined.to_csv('data/data file 2/data_1_1_der.csv', index=False)\n",
    "data_2_der_combined.to_csv('data/data file 2/data_1_2_der.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatization (SavGol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spectrum data\n",
    "data_spectrum = df_normalized_v0.iloc[:, 2:].values\n",
    "\n",
    "# Apply Savitzky-Golay filter for the first derivative\n",
    "first_derivative_savgol = savgol_filter(data_spectrum, window_length=5, polyorder=2, deriv=1, axis=1)\n",
    "\n",
    "# Apply Savitzky-Golay filter for the second derivative\n",
    "second_derivative_savgol = savgol_filter(data_spectrum, window_length=5, polyorder=2, deriv=2, axis=1)\n",
    "\n",
    "# Convert the results back to DataFrame\n",
    "data_1_der_savgol = pd.DataFrame(first_derivative_savgol, columns=df_normalized_v0.columns[2:])\n",
    "data_2_der_savgol = pd.DataFrame(second_derivative_savgol, columns=df_normalized_v0.columns[2:])\n",
    "\n",
    "# Extract the first two columns\n",
    "first_two_columns = df_normalized_v0.iloc[:, :2]\n",
    "\n",
    "# Combine the first two columns with the Savitzky-Golay derivatives\n",
    "data_1_der_savgol_combined = pd.concat([first_two_columns, data_1_der_savgol], axis=1)\n",
    "data_2_der_savgol_combined = pd.concat([first_two_columns, data_2_der_savgol], axis=1)\n",
    "\n",
    "# Export the combined data to CSV\n",
    "data_1_der_savgol_combined.to_csv('data/data file 2/data_1_1_der_savgol.csv', index=False)\n",
    "data_2_der_savgol_combined.to_csv('data/data file 2/data_1_2_der_savgol.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snv(spectrum):\n",
    "    return (spectrum - np.mean(spectrum)) / np.std(spectrum)\n",
    "\n",
    "# Apply SNV to the selected regions\n",
    "df_snv = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_snv[col] = snv(df_snv[col])\n",
    "\n",
    "# Save the SNV data\n",
    "df_snv.to_csv('data/data file 2/data_1_snv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Normal Variate (RNV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnv(spectrum):\n",
    "    random_noise = np.random.normal(0, np.std(spectrum), spectrum.shape)\n",
    "    return spectrum + random_noise\n",
    "\n",
    "# Apply RNV to the selected regions\n",
    "df_rnv = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_rnv[col] = rnv(df_rnv[col])\n",
    "\n",
    "# Save the RNV data\n",
    "df_rnv.to_csv('data/data file 2/data_1_rnv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplicative Scatter Correction (MSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the spectral df_0_selected_regions columns (excluding 'thnoth_name', 'prov_char', and the last two columns)\n",
    "spectral_df_0_selected_regions_columns = df_0_selected_regions.columns[2:]\n",
    "spectral_df_0_selected_regions = df_0_selected_regions[spectral_df_0_selected_regions_columns]\n",
    "\n",
    "# Calculate the mean spectrum across all samples\n",
    "mean_spectrum = spectral_df_0_selected_regions.mean(axis=0)\n",
    "\n",
    "# Perform Mean Centering (MSC)\n",
    "msc_spectral_df_0_selected_regions = spectral_df_0_selected_regions - mean_spectrum\n",
    "\n",
    "# Add back the non-spectral columns to the df_0_selected_regionsframe\n",
    "msc_df_0_selected_regions = df_0_selected_regions[['thnoth_name', 'prov_char']].copy()\n",
    "msc_df_0_selected_regions = pd.concat([msc_df_0_selected_regions, msc_spectral_df_0_selected_regions], axis=1)\n",
    "\n",
    "# Save the MSC preprocessed df_0_selected_regions to a new CSV file\n",
    "msc_df_0_selected_regions.to_csv('data/data file 2/data_1_msc.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the MSC preprocessed df_0_selected_regions\n",
    "#print(msc_df_0_selected_regions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Evaluation (40-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'thnoth_name'\n",
    "\n",
    "# Ensure columns_to_focus are correctly identified\n",
    "numeric_cols_df_0 = df_0_selected_regions.select_dtypes(include=[np.number]).columns.tolist()\n",
    "columns_to_focus = numeric_cols_df_0  # Ensure columns are correctly selected\n",
    "\n",
    "# Classification and evaluation function using 40-fold CV\n",
    "def classify_and_evaluate(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "\n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "\n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=40)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Cross-Validation Accuracy: {np.mean(scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for No Preprocessing:\n",
      "Cross-Validation Accuracy: 0.6895380434782609\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate each preprocessing method\n",
    "print(\"Evaluation for No Preprocessing:\")\n",
    "classify_and_evaluate(df_0_selected_regions, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Baseline Correction:\n",
      "Cross-Validation Accuracy: 0.5828351449275362\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for Baseline Correction:\")\n",
    "df_baseline_corrected_v0z = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "classify_and_evaluate(df_baseline_corrected_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Smoothing:\n",
      "Cross-Validation Accuracy: 0.595606884057971\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for Smoothing:\")\n",
    "df_smoothed_v0z = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "classify_and_evaluate(df_smoothed_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Normalization:\n",
      "Cross-Validation Accuracy: 0.595606884057971\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for Normalization:\")\n",
    "df_normalized_v0z = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "classify_and_evaluate(df_normalized_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for 1-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.842300724637681\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for 1-Derivative Spectroscopy:\")\n",
    "data_1_der_combined_v0z = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "classify_and_evaluate(data_1_der_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for 2-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.8189764492753622\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for 2-Derivative Spectroscopy:\")\n",
    "data_2_der_combined_v0z = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "classify_and_evaluate(data_2_der_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for 1-SG-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.8283061594202898\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for 1-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0z = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for 2-SG-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.8360960144927537\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for 2-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0z = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for SNV:\n",
      "Cross-Validation Accuracy: 0.6895380434782609\n",
      "Evaluation for RNV:\n",
      "Cross-Validation Accuracy: 0.565126811594203\n",
      "Evaluation for MSC:\n",
      "Cross-Validation Accuracy: 0.6895380434782609\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for SNV:\")\n",
    "df_snv_v0z = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "classify_and_evaluate(df_snv_v0z, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for RNV:\")\n",
    "df_rnv_v0z = pd.read_csv('data/data file 2/data_1_rnv.csv')\n",
    "classify_and_evaluate(df_rnv_v0z, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for MSC:\")\n",
    "df_msc_v0z = pd.read_csv('data/data file 2/data_1_msc.csv')\n",
    "classify_and_evaluate(df_msc_v0z, columns_to_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Evaluation (40-fold) -with extra detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'thnoth_name'\n",
    "\n",
    "# Ensure columns_to_focus are correctly identified\n",
    "numeric_cols_df_0 = df_0_selected_regions.select_dtypes(include=[np.number]).columns.tolist()\n",
    "columns_to_focus = numeric_cols_df_0  # Ensure columns are correctly selected\n",
    "\n",
    "# Classification and evaluation function using 40-fold CV with detailed metrics\n",
    "def classify_and_evaluate(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    import numpy as np\n",
    "\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "\n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "\n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Initialize Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=40)\n",
    "\n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    conf_matrices = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average=None))\n",
    "        recalls.append(recall_score(y_test, y_pred, average=None))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average=None))\n",
    "        conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Calculate mean scores\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    mean_recall = np.mean(recalls, axis=0)\n",
    "    mean_f1 = np.mean(f1_scores, axis=0)\n",
    "    mean_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Cross-Validation Accuracy: {mean_accuracy}')\n",
    "    print(f'Precision per class: {mean_precision}')\n",
    "    print(f'Recall per class: {mean_recall}')\n",
    "    print(f'F1-score per class: {mean_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for No Preprocessing:\n",
      "Cross-Validation Accuracy: 0.9513392857142857\n",
      "Precision per class: [0.95375    0.97166667]\n",
      "Recall per class: [0.96041667 0.93958333]\n",
      "F1-score per class: [0.95015873 0.94888889]\n",
      "Evaluation for Baseline Correction:\n",
      "Cross-Validation Accuracy: 0.9254464285714287\n",
      "Precision per class: [0.96083333 0.93011905]\n",
      "Recall per class: [0.9        0.94791667]\n",
      "F1-score per class: [0.91236111 0.9278842 ]\n",
      "Evaluation for Smoothing:\n",
      "Cross-Validation Accuracy: 0.9223214285714286\n",
      "Precision per class: [0.96970238 0.90875   ]\n",
      "Recall per class: [0.88958333 0.95625   ]\n",
      "F1-score per class: [0.91915404 0.91922619]\n",
      "Evaluation for Normalization:\n",
      "Cross-Validation Accuracy: 0.9223214285714286\n",
      "Precision per class: [0.96970238 0.90875   ]\n",
      "Recall per class: [0.88958333 0.95625   ]\n",
      "F1-score per class: [0.91915404 0.91922619]\n",
      "Evaluation for 1-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.9089285714285715\n",
      "Precision per class: [0.96041667 0.88958333]\n",
      "Recall per class: [0.86458333 0.95625   ]\n",
      "F1-score per class: [0.89946429 0.91444444]\n",
      "Evaluation for 2-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.8959821428571431\n",
      "Precision per class: [0.95333333 0.88083333]\n",
      "Recall per class: [0.85208333 0.94166667]\n",
      "F1-score per class: [0.88698413 0.89892857]\n",
      "Evaluation for 1-SG-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.9\n",
      "Precision per class: [0.95416667 0.88166667]\n",
      "Recall per class: [0.85208333 0.94791667]\n",
      "F1-score per class: [0.88821429 0.90632937]\n",
      "Evaluation for 2-SG-Derivative Spectroscopy:\n",
      "Cross-Validation Accuracy: 0.8991071428571429\n",
      "Precision per class: [0.96166667 0.87458333]\n",
      "Recall per class: [0.84583333 0.95625   ]\n",
      "F1-score per class: [0.8868254  0.90543651]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each preprocessing method\n",
    "print(\"Evaluation for No Preprocessing:\")\n",
    "classify_and_evaluate(df_0_selected_regions, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for Baseline Correction:\")\n",
    "df_baseline_corrected_v0y = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "classify_and_evaluate(df_baseline_corrected_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for Smoothing:\")\n",
    "df_smoothed_v0y = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "classify_and_evaluate(df_smoothed_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for Normalization:\")\n",
    "df_normalized_v0y = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "classify_and_evaluate(df_normalized_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 1-Derivative Spectroscopy:\")\n",
    "df_derivative_v0y = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "classify_and_evaluate(df_derivative_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 2-Derivative Spectroscopy:\")\n",
    "data_2_der_combined_v0y = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "classify_and_evaluate(data_2_der_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 1-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for 2-SG-Derivative Spectroscopy:\")\n",
    "data_1_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "classify_and_evaluate(data_1_der_savgol_combined_v0y, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for SNV:\n",
      "Cross-Validation Accuracy: 0.9383928571428573\n",
      "Precision per class: [0.95291667 0.94125   ]\n",
      "Recall per class: [0.92916667 0.94583333]\n",
      "F1-score per class: [0.9356746  0.93821429]\n",
      "Evaluation for RNV:\n",
      "Cross-Validation Accuracy: 0.7058035714285714\n",
      "Precision per class: [0.75958333 0.7039881 ]\n",
      "Recall per class: [0.64583333 0.7625    ]\n",
      "F1-score per class: [0.67210317 0.71408189]\n",
      "Evaluation for MSC:\n",
      "Cross-Validation Accuracy: 0.9383928571428573\n",
      "Precision per class: [0.95291667 0.94125   ]\n",
      "Recall per class: [0.92916667 0.94583333]\n",
      "F1-score per class: [0.9356746  0.93821429]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for SNV:\")\n",
    "df_snv_v0y = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "classify_and_evaluate(df_snv_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for RNV:\")\n",
    "df_rnv_v0y = pd.read_csv('data/data file 2/data_1_rnv.csv')\n",
    "classify_and_evaluate(df_rnv_v0y, columns_to_focus)\n",
    "\n",
    "print(\"Evaluation for MSC:\")\n",
    "df_msc_v0y = pd.read_csv('data/data file 2/data_1_msc.csv')\n",
    "classify_and_evaluate(df_msc_v0y, columns_to_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Evaluation using LOGO-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    all_y_test = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "    # Calculate overall metrics\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    precision = precision_score(all_y_test, all_y_pred, average=None)\n",
    "    recall = recall_score(all_y_test, all_y_pred, average=None)\n",
    "    f1 = f1_score(all_y_test, all_y_pred, average=None)\n",
    "    conf_matrix = confusion_matrix(all_y_test, all_y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Mean Accuracy: {mean_accuracy}')\n",
    "    print(f'Precision per class: {precision}')\n",
    "    print(f'Recall per class: {recall}')\n",
    "    print(f'F1-score per class: {f1}')\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGO-CV Evaluation for No Preprocessing:\n",
      "Mean Accuracy: 0.6174770768717993\n",
      "Precision per class: [0.48209366 0.48873484]\n",
      "Recall per class: [0.37234043 0.6       ]\n",
      "F1-score per class: [0.42016807 0.53868195]\n",
      "LOGO-CV Evaluation for Baseline Correction:\n",
      "Mean Accuracy: 0.5380708527961201\n",
      "Precision per class: [0.38016529 0.42461005]\n",
      "Recall per class: [0.29361702 0.5212766 ]\n",
      "F1-score per class: [0.33133253 0.46800382]\n",
      "LOGO-CV Evaluation for Smoothing:\n",
      "Mean Accuracy: 0.5687517307515114\n",
      "Precision per class: [0.46782178 0.47574627]\n",
      "Recall per class: [0.40212766 0.54255319]\n",
      "F1-score per class: [0.43249428 0.50695825]\n",
      "LOGO-CV Evaluation for Normalization:\n",
      "Mean Accuracy: 0.5687517307515114\n",
      "Precision per class: [0.46782178 0.47574627]\n",
      "Recall per class: [0.40212766 0.54255319]\n",
      "F1-score per class: [0.43249428 0.50695825]\n",
      "LOGO-CV Evaluation for 1-Derivative Spectroscopy:\n",
      "Mean Accuracy: 0.8419935146574473\n",
      "Precision per class: [0.79578947 0.80215054]\n",
      "Recall per class: [0.80425532 0.79361702]\n",
      "F1-score per class: [0.8        0.79786096]\n",
      "LOGO-CV Evaluation for 2-Derivative Spectroscopy:\n",
      "Mean Accuracy: 0.8324215742431035\n",
      "Precision per class: [0.78431373 0.77130977]\n",
      "Recall per class: [0.76595745 0.7893617 ]\n",
      "F1-score per class: [0.77502691 0.78023134]\n",
      "LOGO-CV Evaluation for 1-SG-Derivative Spectroscopy:\n",
      "Mean Accuracy: 0.8581802072865224\n",
      "Precision per class: [0.78846154 0.78601695]\n",
      "Recall per class: [0.78510638 0.7893617 ]\n",
      "F1-score per class: [0.78678038 0.78768577]\n",
      "LOGO-CV Evaluation for 2-SG-Derivative Spectroscopy:\n",
      "Mean Accuracy: 0.8352863314807095\n",
      "Precision per class: [0.79955947 0.77983539]\n",
      "Recall per class: [0.77234043 0.80638298]\n",
      "F1-score per class: [0.78571429 0.79288703]\n",
      "LOGO-CV Evaluation for SNV:\n",
      "Mean Accuracy: 0.6174770768717993\n",
      "Precision per class: [0.48209366 0.48873484]\n",
      "Recall per class: [0.37234043 0.6       ]\n",
      "F1-score per class: [0.42016807 0.53868195]\n",
      "LOGO-CV Evaluation for RNV:\n",
      "Mean Accuracy: 0.38642489202391267\n",
      "Precision per class: [0.21149425 0.25148515]\n",
      "Recall per class: [0.19574468 0.27021277]\n",
      "F1-score per class: [0.20331492 0.26051282]\n",
      "LOGO-CV Evaluation for MSC:\n",
      "Mean Accuracy: 0.6174770768717993\n",
      "Precision per class: [0.48209366 0.48873484]\n",
      "Recall per class: [0.37234043 0.6       ]\n",
      "F1-score per class: [0.42016807 0.53868195]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each preprocessing method using LOGO-CV with detailed metrics\n",
    "print(\"LOGO-CV Evaluation for No Preprocessing:\")\n",
    "conf_matrix_no_preprocessing_v0x = classify_and_evaluate_logo_cv_detailed(df_0_selected_regions, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for Baseline Correction:\")\n",
    "df_baseline_corrected_v0x = pd.read_csv('data/data file 2/data_1_bslcrct.csv')\n",
    "conf_matrix_baseline_v0x = classify_and_evaluate_logo_cv_detailed(df_baseline_corrected_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for Smoothing:\")\n",
    "df_smoothed_v0x = pd.read_csv('data/data file 2/data_1_smoothed.csv')\n",
    "conf_matrix_smoothing_v0x = classify_and_evaluate_logo_cv_detailed(df_smoothed_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for Normalization:\")\n",
    "df_normalized_v0x = pd.read_csv('data/data file 2/data_1_normalized.csv')\n",
    "conf_matrix_normalization_v0x = classify_and_evaluate_logo_cv_detailed(df_normalized_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "df_1_derivative_v0x = pd.read_csv('data/data file 2/data_1_1_der.csv')\n",
    "conf_matrix_1_derivative_v0x = classify_and_evaluate_logo_cv_detailed(df_1_derivative_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 2-Derivative Spectroscopy:\")\n",
    "df_2_derivative_v0x = pd.read_csv('data/data file 2/data_1_2_der.csv')\n",
    "conf_matrix_2_derivative_v0x = classify_and_evaluate_logo_cv_detailed(df_2_derivative_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-SG-Derivative Spectroscopy:\")\n",
    "df_1_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_1_der_savgol.csv')\n",
    "conf_matrix_1_sg_v0x = classify_and_evaluate_logo_cv_detailed(df_1_der_savgol_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 2-SG-Derivative Spectroscopy:\")\n",
    "df_2_der_savgol_combined_v0y = pd.read_csv('data/data file 2/data_1_2_der_savgol.csv')\n",
    "conf_matrix_2_sg_v0x = classify_and_evaluate_logo_cv_detailed(df_2_der_savgol_combined_v0y, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for SNV:\")\n",
    "df_snv_v0x = pd.read_csv('data/data file 2/data_1_snv.csv')\n",
    "conf_matrix_snv_v0x = classify_and_evaluate_logo_cv_detailed(df_snv_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for RNV:\")\n",
    "df_rnv_v0x = pd.read_csv('data/data file 2/data_1_rnv.csv')\n",
    "conf_matrix_rnv_v0x = classify_and_evaluate_logo_cv_detailed(df_rnv_v0x, columns_to_focus)\n",
    "\n",
    "print(\"LOGO-CV Evaluation for MSC:\")\n",
    "df_msc_v0x = pd.read_csv('data/data file 2/data_1_msc.csv')\n",
    "conf_matrix_msc_v0x = classify_and_evaluate_logo_cv_detailed(df_msc_v0x, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9194485925414478\n",
      "Precision per class: [0.93984962 0.84210526]\n",
      "Recall per class: [0.82236842 0.94736842]\n",
      "F1-score per class: [0.87719298 0.89164087]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_1_sg_v0x = classify_and_evaluate_logo_cv_detailed(df_1_der_savgol_combined_v0y, columns_to_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix in a tabular format\n",
    "def display_confusion_matrix(conf_matrix, class_labels):\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "    print(df_cm)\n",
    "\n",
    "# Ensure LabelEncoder is defined and class labels are set\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the target variable and fit LabelEncoder\n",
    "target = 'thnoth_name'\n",
    "le = LabelEncoder()\n",
    "le.fit(df_0_selected_regions[target])\n",
    "class_labels = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for No Preprocessing:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai        86    66\n",
      "Thai            15   137\n",
      "Confusion Matrix for Baseline Correction:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       129    23\n",
      "Thai            10   142\n",
      "Confusion Matrix for Smoothing:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       134    18\n",
      "Thai             6   146\n",
      "Confusion Matrix for Normalization:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       133    19\n",
      "Thai             7   145\n",
      "Confusion Matrix for Derivative Spectroscopy:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       125    27\n",
      "Thai             6   146\n",
      "Confusion Matrix for Derivative Spectroscopy:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       122    30\n",
      "Thai            11   141\n",
      "Confusion Matrix for Derivative Spectroscopy:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       125    27\n",
      "Thai             8   144\n",
      "Confusion Matrix for Derivative Spectroscopy:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       119    33\n",
      "Thai            10   142\n",
      "Confusion Matrix for SNV:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai        74    78\n",
      "Thai            22   130\n",
      "Confusion Matrix for RNV:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai        79    73\n",
      "Thai            51   101\n",
      "Confusion Matrix for MSC:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai        74    78\n",
      "Thai            22   130\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrices for each preprocessing method\n",
    "print(\"Confusion Matrix for No Preprocessing:\")\n",
    "display_confusion_matrix(conf_matrix_no_preprocessing_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Baseline Correction:\")\n",
    "display_confusion_matrix(conf_matrix_baseline_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Smoothing:\")\n",
    "display_confusion_matrix(conf_matrix_smoothing_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Normalization:\")\n",
    "display_confusion_matrix(conf_matrix_normalization_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_1_derivative_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_2_derivative_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_1_sg_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for Derivative Spectroscopy:\")\n",
    "display_confusion_matrix(conf_matrix_2_sg_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for SNV:\")\n",
    "display_confusion_matrix(conf_matrix_snv_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for RNV:\")\n",
    "display_confusion_matrix(conf_matrix_rnv_v0x, class_labels)\n",
    "\n",
    "print(\"Confusion Matrix for MSC:\")\n",
    "display_confusion_matrix(conf_matrix_msc_v0x, class_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
