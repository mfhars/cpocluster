{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_0 = pd.read_csv(r\"C:\\Users\\pingk\\Downloads\\fadhli nitip\\asik_NIR_DIST_3b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prov_char country_char           wavenumber     11544     11540     11536  \\\n",
      "0       KAX           ID  ID-KAX-088-2401-001  0.290252  0.290122  0.290044   \n",
      "1       KBX           ID  ID-KBX-068-2306-003  0.522845  0.522798  0.522826   \n",
      "2       BBX           ID  ID-BBX-095-2401-004 -0.144108 -0.144008 -0.143893   \n",
      "3       SUX           ID  ID-SUX-074-2311-001  0.333905  0.333777  0.333785   \n",
      "4       SUX           ID  ID-SUX-073-2311-001  1.522433  1.521460  1.521133   \n",
      "\n",
      "      11532     11528     11524     11520  ...      3964      3960      3956  \\\n",
      "0  0.290029  0.290042  0.289978  0.289851  ...  3.558086  3.542757  3.530849   \n",
      "1  0.522669  0.522414  0.522217  0.522070  ...  3.680422  3.655416  3.629388   \n",
      "2 -0.143777 -0.143686 -0.143667 -0.143678  ...  3.650478  3.623180  3.614590   \n",
      "3  0.333700  0.333522  0.333453  0.333446  ...  3.601331  3.566453  3.539593   \n",
      "4  1.521072  1.521494  1.522300  1.521840  ...  4.103365  4.125110  4.113971   \n",
      "\n",
      "       3952  tgp_name  dgp_name  fgp_name  country_name  thnoth_name  \\\n",
      "0  3.501222   Group 3   Group 2   Group 4     Indonesia     Non-Thai   \n",
      "1  3.606223   Group 3   Group 2   Group 4     Indonesia     Non-Thai   \n",
      "2  3.581875   Group 3   Group 2   Group 3     Indonesia     Non-Thai   \n",
      "3  3.512285   Group 3   Group 2   Group 3     Indonesia     Non-Thai   \n",
      "4  4.055192   Group 3   Group 2   Group 3     Indonesia     Non-Thai   \n",
      "\n",
      "   thnoth_name_encoded  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n",
      "\n",
      "[5 rows x 1908 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_0.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regions of interest\n",
    "regions_of_interest = [\n",
    "    (4641, 4681), (4867, 5510), (5657, 5826), (7057, 7097),\n",
    "    (7169, 7209), (8238, 8278)\n",
    "]\n",
    "\n",
    "# Extract columns corresponding to the regions of interest\n",
    "columns_to_focus = []\n",
    "for start, end in regions_of_interest:\n",
    "    columns_to_focus.extend([col for col in df_0.columns[4:-7] if start <= float(col) <= end])\n",
    "\n",
    "# Create a new DataFrame with the selected regions\n",
    "df_0_selected_regions = df_0[columns_to_focus]\n",
    "\n",
    "# Combine the selected regions with the target column and other relevant columns\n",
    "df_0_selected_regions = pd.concat([df_0[['thnoth_name', 'prov_char']], df_0_selected_regions], axis=1)\n",
    "\n",
    "# Save the DataFrame for further processing\n",
    "#df_0_selected_regions.to_csv('data/data file 2b/data_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thnoth_name</th>\n",
       "      <th>prov_char</th>\n",
       "      <th>4680</th>\n",
       "      <th>4676</th>\n",
       "      <th>4672</th>\n",
       "      <th>4668</th>\n",
       "      <th>4664</th>\n",
       "      <th>4660</th>\n",
       "      <th>4656</th>\n",
       "      <th>4652</th>\n",
       "      <th>...</th>\n",
       "      <th>8276</th>\n",
       "      <th>8272</th>\n",
       "      <th>8268</th>\n",
       "      <th>8264</th>\n",
       "      <th>8260</th>\n",
       "      <th>8256</th>\n",
       "      <th>8252</th>\n",
       "      <th>8248</th>\n",
       "      <th>8244</th>\n",
       "      <th>8240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>KAX</td>\n",
       "      <td>1.145221</td>\n",
       "      <td>1.161998</td>\n",
       "      <td>1.183733</td>\n",
       "      <td>1.206279</td>\n",
       "      <td>1.221476</td>\n",
       "      <td>1.219369</td>\n",
       "      <td>1.195433</td>\n",
       "      <td>1.155057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693094</td>\n",
       "      <td>0.696532</td>\n",
       "      <td>0.699208</td>\n",
       "      <td>0.701041</td>\n",
       "      <td>0.702028</td>\n",
       "      <td>0.702149</td>\n",
       "      <td>0.701310</td>\n",
       "      <td>0.699461</td>\n",
       "      <td>0.696617</td>\n",
       "      <td>0.692720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>KBX</td>\n",
       "      <td>1.100158</td>\n",
       "      <td>1.117663</td>\n",
       "      <td>1.140348</td>\n",
       "      <td>1.163641</td>\n",
       "      <td>1.178847</td>\n",
       "      <td>1.175626</td>\n",
       "      <td>1.149462</td>\n",
       "      <td>1.106238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827193</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.833110</td>\n",
       "      <td>0.834886</td>\n",
       "      <td>0.835800</td>\n",
       "      <td>0.835858</td>\n",
       "      <td>0.835008</td>\n",
       "      <td>0.833129</td>\n",
       "      <td>0.830211</td>\n",
       "      <td>0.826278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>BBX</td>\n",
       "      <td>0.873460</td>\n",
       "      <td>0.891096</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.937998</td>\n",
       "      <td>0.954190</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>0.926066</td>\n",
       "      <td>0.882441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370219</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.376443</td>\n",
       "      <td>0.378311</td>\n",
       "      <td>0.379332</td>\n",
       "      <td>0.379466</td>\n",
       "      <td>0.378665</td>\n",
       "      <td>0.376875</td>\n",
       "      <td>0.374042</td>\n",
       "      <td>0.370139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>SUX</td>\n",
       "      <td>1.014767</td>\n",
       "      <td>1.031323</td>\n",
       "      <td>1.052854</td>\n",
       "      <td>1.075045</td>\n",
       "      <td>1.089551</td>\n",
       "      <td>1.086283</td>\n",
       "      <td>1.060706</td>\n",
       "      <td>1.018413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694977</td>\n",
       "      <td>0.698438</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.702996</td>\n",
       "      <td>0.703988</td>\n",
       "      <td>0.704090</td>\n",
       "      <td>0.703278</td>\n",
       "      <td>0.701477</td>\n",
       "      <td>0.698633</td>\n",
       "      <td>0.694729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Thai</td>\n",
       "      <td>SUX</td>\n",
       "      <td>1.520511</td>\n",
       "      <td>1.536409</td>\n",
       "      <td>1.557498</td>\n",
       "      <td>1.579159</td>\n",
       "      <td>1.592749</td>\n",
       "      <td>1.588327</td>\n",
       "      <td>1.561828</td>\n",
       "      <td>1.519022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606612</td>\n",
       "      <td>1.609559</td>\n",
       "      <td>1.611674</td>\n",
       "      <td>1.613343</td>\n",
       "      <td>1.614402</td>\n",
       "      <td>1.614270</td>\n",
       "      <td>1.612957</td>\n",
       "      <td>1.610735</td>\n",
       "      <td>1.607516</td>\n",
       "      <td>1.603303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  thnoth_name prov_char      4680      4676      4672      4668      4664  \\\n",
       "0    Non-Thai       KAX  1.145221  1.161998  1.183733  1.206279  1.221476   \n",
       "1    Non-Thai       KBX  1.100158  1.117663  1.140348  1.163641  1.178847   \n",
       "2    Non-Thai       BBX  0.873460  0.891096  0.914072  0.937998  0.954190   \n",
       "3    Non-Thai       SUX  1.014767  1.031323  1.052854  1.075045  1.089551   \n",
       "4    Non-Thai       SUX  1.520511  1.536409  1.557498  1.579159  1.592749   \n",
       "\n",
       "       4660      4656      4652  ...      8276      8272      8268      8264  \\\n",
       "0  1.219369  1.195433  1.155057  ...  0.693094  0.696532  0.699208  0.701041   \n",
       "1  1.175626  1.149462  1.106238  ...  0.827193  0.830521  0.833110  0.834886   \n",
       "2  0.951890  0.926066  0.882441  ...  0.370219  0.373736  0.376443  0.378311   \n",
       "3  1.086283  1.060706  1.018413  ...  0.694977  0.698438  0.701122  0.702996   \n",
       "4  1.588327  1.561828  1.519022  ...  1.606612  1.609559  1.611674  1.613343   \n",
       "\n",
       "       8260      8256      8252      8248      8244      8240  \n",
       "0  0.702028  0.702149  0.701310  0.699461  0.696617  0.692720  \n",
       "1  0.835800  0.835858  0.835008  0.833129  0.830211  0.826278  \n",
       "2  0.379332  0.379466  0.378665  0.376875  0.374042  0.370139  \n",
       "3  0.703988  0.704090  0.703278  0.701477  0.698633  0.694729  \n",
       "4  1.614402  1.614270  1.612957  1.610735  1.607516  1.603303  \n",
       "\n",
       "[5 rows x 245 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0_selected_regions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Function for baseline correction with dynamic window length\n",
    "def baseline_correction(spectrum, default_window_length=15, polyorder=3):\n",
    "    spectrum_length = len(spectrum)\n",
    "    if spectrum_length < default_window_length:\n",
    "        window_length = spectrum_length // 2 * 2 + 1  # Make window length odd and less than the size of the spectrum\n",
    "    else:\n",
    "        window_length = default_window_length\n",
    "    baseline = savgol_filter(spectrum, window_length, polyorder, mode='nearest')\n",
    "    corrected_spectrum = spectrum - baseline\n",
    "    return corrected_spectrum\n",
    "\n",
    "# Apply baseline correction\n",
    "df_baseline_corrected_v0 = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_baseline_corrected_v0[col] = baseline_correction(df_baseline_corrected_v0[col])\n",
    "\n",
    "# Save the baseline corrected data\n",
    "#df_baseline_corrected_v0.to_csv('data/data file 2b/data_1_bslcrct.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavGol Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Savitzky-Golay smoothing\n",
    "def savitzky_golay_smoothing(spectrum, default_window_length=11, polyorder=2):\n",
    "    window_length = min(default_window_length, len(spectrum) // 2 * 2 + 1)  # Make window length odd and less than or equal to the size of the spectrum\n",
    "    if window_length < 3:  # Ensure window length is at least 3\n",
    "        window_length = 3\n",
    "    return savgol_filter(spectrum, window_length, polyorder, mode='nearest')  # Set mode to 'nearest'\n",
    "\n",
    "# Apply smoothing\n",
    "df_smoothed_v0 = df_baseline_corrected_v0.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_smoothed_v0[col] = savitzky_golay_smoothing(df_smoothed_v0[col])\n",
    "\n",
    "# Save the smoothed data\n",
    "#df_smoothed_v0.to_csv('data/data file 2b/data_1_smoothed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for normalization (Min-Max scaling)\n",
    "def min_max_normalization(spectrum):\n",
    "    return (spectrum - np.min(spectrum)) / (np.max(spectrum) - np.min(spectrum))\n",
    "\n",
    "# Apply normalization\n",
    "df_normalized_v0 = df_smoothed_v0.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_normalized_v0[col] = min_max_normalization(df_normalized_v0[col])\n",
    "\n",
    "# Save the normalized data\n",
    "#df_normalized_v0.to_csv('data/data file 2b/data_1_normalized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatization (np.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first derivative using np.gradient\n",
    "data_spectrum = df_normalized_v0.iloc[:, 2:].values\n",
    "first_derivative_np = np.gradient(data_spectrum, axis=1)\n",
    "\n",
    "# Calculate the second derivative using np.gradient\n",
    "second_derivative_np = np.gradient(first_derivative_np, axis=1)\n",
    "\n",
    "# Convert the results back to DataFrame\n",
    "data_1_der_np = pd.DataFrame(first_derivative_np, columns=df_normalized_v0.columns[2:])\n",
    "data_2_der_np = pd.DataFrame(second_derivative_np, columns=df_normalized_v0.columns[2:])\n",
    "\n",
    "# Combine the first two columns from the original dataset with the np.gradient derivatives\n",
    "\n",
    "# Extract the first two columns\n",
    "first_two_columns = df_normalized_v0.iloc[:, :2]\n",
    "\n",
    "# Combine the first two columns with the derivatives\n",
    "data_1_der_combined = pd.concat([first_two_columns, data_1_der_np], axis=1)\n",
    "data_2_der_combined = pd.concat([first_two_columns, data_2_der_np], axis=1)\n",
    "\n",
    "# Export the combined data to CSV\n",
    "#data_1_der_combined.to_csv('data/data file 2b/data_1_1_der.csv', index=False)\n",
    "#data_2_der_combined.to_csv('data/data file 2b/data_1_2_der.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatization (SavGol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spectrum data\n",
    "data_spectrum = df_normalized_v0.iloc[:, 2:].values\n",
    "\n",
    "# Apply Savitzky-Golay filter for the first derivative\n",
    "first_derivative_savgol = savgol_filter(data_spectrum, window_length=5, polyorder=2, deriv=1, axis=1)\n",
    "\n",
    "# Apply Savitzky-Golay filter for the second derivative\n",
    "second_derivative_savgol = savgol_filter(data_spectrum, window_length=5, polyorder=2, deriv=2, axis=1)\n",
    "\n",
    "# Convert the results back to DataFrame\n",
    "data_1_der_savgol = pd.DataFrame(first_derivative_savgol, columns=df_normalized_v0.columns[2:])\n",
    "data_2_der_savgol = pd.DataFrame(second_derivative_savgol, columns=df_normalized_v0.columns[2:])\n",
    "\n",
    "# Extract the first two columns\n",
    "first_two_columns = df_normalized_v0.iloc[:, :2]\n",
    "\n",
    "# Combine the first two columns with the Savitzky-Golay derivatives\n",
    "data_1_der_savgol_combined = pd.concat([first_two_columns, data_1_der_savgol], axis=1)\n",
    "data_2_der_savgol_combined = pd.concat([first_two_columns, data_2_der_savgol], axis=1)\n",
    "\n",
    "# Export the combined data to CSV\n",
    "#data_1_der_savgol_combined.to_csv('data/data file 2b/data_1_1_der_savgol.csv', index=False)\n",
    "#data_2_der_savgol_combined.to_csv('data/data file 2b/data_1_2_der_savgol.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snv(spectrum):\n",
    "    return (spectrum - np.mean(spectrum)) / np.std(spectrum)\n",
    "\n",
    "# Apply SNV to the selected regions\n",
    "df_snv = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_snv[col] = snv(df_snv[col])\n",
    "\n",
    "# Save the SNV data\n",
    "#df_snv.to_csv('data/data file 2b/data_1_snv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Normal Variate (RNV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnv(spectrum):\n",
    "    random_noise = np.random.normal(0, np.std(spectrum), spectrum.shape)\n",
    "    return spectrum + random_noise\n",
    "\n",
    "# Apply RNV to the selected regions\n",
    "df_rnv = df_0_selected_regions.copy()\n",
    "for col in columns_to_focus:\n",
    "    df_rnv[col] = rnv(df_rnv[col])\n",
    "\n",
    "# Save the RNV data\n",
    "#df_rnv.to_csv('data/data file 2b/data_1_rnv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplicative Scatter Correction (MSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the spectral df_0_selected_regions columns (excluding 'thnoth_name', 'prov_char', and the last two columns)\n",
    "spectral_df_0_selected_regions_columns = df_0_selected_regions.columns[2:]\n",
    "spectral_df_0_selected_regions = df_0_selected_regions[spectral_df_0_selected_regions_columns]\n",
    "\n",
    "# Calculate the mean spectrum across all samples\n",
    "mean_spectrum = spectral_df_0_selected_regions.mean(axis=0)\n",
    "\n",
    "# Perform Mean Centering (MSC)\n",
    "msc_spectral_df_0_selected_regions = spectral_df_0_selected_regions - mean_spectrum\n",
    "\n",
    "# Add back the non-spectral columns to the df_0_selected_regionsframe\n",
    "msc_df_0_selected_regions = df_0_selected_regions[['thnoth_name', 'prov_char']].copy()\n",
    "msc_df_0_selected_regions = pd.concat([msc_df_0_selected_regions, msc_spectral_df_0_selected_regions], axis=1)\n",
    "\n",
    "# Save the MSC preprocessed df_0_selected_regions to a new CSV file\n",
    "#msc_df_0_selected_regions.to_csv('data/data file 2b/data_1_msc.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the MSC preprocessed df_0_selected_regions\n",
    "#print(msc_df_0_selected_regions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define the target variable\n",
    "target = 'thnoth_name'\n",
    "\n",
    "# Ensure columns_to_focus are correctly identified\n",
    "numeric_cols_df_0 = df_0_selected_regions.select_dtypes(include=[np.number]).columns.tolist()\n",
    "columns_to_focus = numeric_cols_df_0  # Ensure columns are correctly selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-Step Implementation for Classifiers Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smoothed dataset\n",
    "df_1dernp_v00 = pd.read_csv('data/data file 2/data_1_2_der.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Target Variable and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target_v00 variable and feature columns\n",
    "target_v00 = 'thnoth_name'\n",
    "features_v00 = df_1dernp_v00.columns.difference(['thnoth_name', 'prov_char'])\n",
    "X = df_1dernp_v00[features_v00]\n",
    "y = df_1dernp_v00[target_v00]\n",
    "groups = df_1dernp_v00['prov_char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-One-Group-Out CV - Overall Test Accuracy: 0.8351063829787234\n",
      "Leave-One-Group-Out CV SVM Model Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Thai       0.94      0.72      0.81       470\n",
      "        Thai       0.77      0.95      0.85       470\n",
      "\n",
      "    accuracy                           0.84       940\n",
      "   macro avg       0.85      0.84      0.83       940\n",
      "weighted avg       0.85      0.84      0.83       940\n",
      "\n",
      "Confusion Matrix:\n",
      "          Non-Thai  Thai\n",
      "Non-Thai       338   132\n",
      "Thai            23   447\n",
      "Class: Non-Thai\n",
      "precision: 0.9362880886426593\n",
      "recall: 0.7191489361702128\n",
      "f1-score: 0.8134777376654633\n",
      "support: 470.0\n",
      "\n",
      "Class: Thai\n",
      "precision: 0.772020725388601\n",
      "recall: 0.951063829787234\n",
      "f1-score: 0.8522402287893232\n",
      "support: 470.0\n",
      "\n",
      "accuracy: 0.8351063829787234\n",
      "\n",
      "Class: macro avg\n",
      "precision: 0.8541544070156302\n",
      "recall: 0.8351063829787234\n",
      "f1-score: 0.8328589832273932\n",
      "support: 940.0\n",
      "\n",
      "Class: weighted avg\n",
      "precision: 0.8541544070156301\n",
      "recall: 0.8351063829787234\n",
      "f1-score: 0.8328589832273933\n",
      "support: 940.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_svm = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_svm2_all = []\n",
    "y_pred_svm2_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled_svm, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled_svm[train_index], X_scaled_svm[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_svm2_all.extend(y_test)\n",
    "    y_pred_svm2_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_svm2_all, y_pred_svm2_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_svm1_logo = classification_report(y_true_svm2_all, y_pred_svm2_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV SVM Model Classification Report\")\n",
    "print(classification_report(y_true_svm2_all, y_pred_svm2_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_svm2_all, y_pred_svm2_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_svm1_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest (RF) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGO-CV Evaluation for 1-Derivative Spectroscopy:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'columns_to_focus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conf_matrix\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOGO-CV Evaluation for 1-Derivative Spectroscopy:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m conf_matrix_1_derivative_v03 \u001b[38;5;241m=\u001b[39m classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, \u001b[43mcolumns_to_focus\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'columns_to_focus' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and store results\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "    precision = precision_score(y_true_all, y_pred_all, average=None)\n",
    "    recall = recall_score(y_true_all, y_pred_all, average=None)\n",
    "    f1 = f1_score(y_true_all, y_pred_all, average=None)\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "    print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "    \n",
    "    # Print the confusion matrix in text format\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_df)\n",
    "    \n",
    "    # Print the detailed results\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{class_name}: {metrics}\")\n",
    "        print()\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "conf_matrix_1_derivative_v03 = classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    all_y_test = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        all_y_test.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "    # Calculate overall metrics\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    precision = precision_score(all_y_test, all_y_pred, average=None)\n",
    "    recall = recall_score(all_y_test, all_y_pred, average=None)\n",
    "    f1 = f1_score(all_y_test, all_y_pred, average=None)\n",
    "    conf_matrix = confusion_matrix(all_y_test, all_y_pred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Mean Accuracy: {mean_accuracy}')\n",
    "    print(f'Precision per class: {precision}')\n",
    "    print(f'Recall per class: {recall}')\n",
    "    print(f'F1-score per class: {f1}')\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "conf_matrix_1_derivative_v03 = classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Classification and evaluation function using LOGO-CV with detailed metrics\n",
    "def classify_and_evaluate_logo_cv_detailed(df, columns):\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target])\n",
    "    \n",
    "    # Define features\n",
    "    X = df[columns]\n",
    "    \n",
    "    # Initialize the classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Initialize LOGO-CV\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = df['prov_char']\n",
    "    \n",
    "    # Arrays to store results\n",
    "    accuracies = []\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    # Perform LOGO-CV\n",
    "    for train_idx, test_idx in logo.split(X, y, groups=groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and store results\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = np.mean(accuracies)\n",
    "    precision = precision_score(y_true_all, y_pred_all, average=None)\n",
    "    recall = recall_score(y_true_all, y_pred_all, average=None)\n",
    "    f1 = f1_score(y_true_all, y_pred_all, average=None)\n",
    "    conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true_all, y_pred_all, target_names=le.classes_, output_dict=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "    print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=le.classes_))\n",
    "    \n",
    "    # Print the confusion matrix in text format\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_df)\n",
    "    \n",
    "    # Print the detailed results\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{class_name}: {metrics}\")\n",
    "        print()\n",
    "    \n",
    "    # Return confusion matrix for presentation\n",
    "    return conf_matrix\n",
    "\n",
    "print(\"LOGO-CV Evaluation for 1-Derivative Spectroscopy:\")\n",
    "conf_matrix_1_derivative_v03 = classify_and_evaluate_logo_cv_detailed(df_1dernp_v00, columns_to_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "y_true_rf3_all = []\n",
    "y_pred_rf3_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_rf3_all.extend(y_test)\n",
    "    y_pred_rf3_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = np.mean(accuracies) #accuracy_score(y_true_rf3_all, y_pred_rf3_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_rf_logo = classification_report(y_true_rf3_all, y_pred_rf3_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Random Forest Model Classification Report\")\n",
    "print(classification_report(y_true_rf3_all, y_pred_rf3_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_rf3_all, y_pred_rf3_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_rf_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees (ET) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the Extra Trees classifier\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_et_all = []\n",
    "y_pred_et_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    et.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = et.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_et_all.extend(y_test)\n",
    "    y_pred_et_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_et_all, y_pred_et_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_et_logo = classification_report(y_true_et_all, y_pred_et_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Extra Trees Model Classification Report\")\n",
    "print(classification_report(y_true_et_all, y_pred_et_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_et_all, y_pred_et_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_et_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_knn_all = []\n",
    "y_pred_knn_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_knn_all.extend(y_test)\n",
    "    y_pred_knn_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_knn_all, y_pred_knn_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_knn_logo = classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV kNN Model Classification Report\")\n",
    "print(classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_knn_all, y_pred_knn_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_knn_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Standardize the features after SNV transformation\n",
    "scaler = StandardScaler()\n",
    "X_scaled_knn = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize the kNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Initialize LOGO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "y_true_knn_all = []\n",
    "y_pred_knn_all = []\n",
    "\n",
    "# Perform LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled_knn, y_encoded, groups):\n",
    "    X_train, X_test = X_scaled_knn[train_index], X_scaled_knn[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_knn_all.extend(y_test)\n",
    "    y_pred_knn_all.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true_knn_all, y_pred_knn_all)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Overall Test Accuracy: {overall_accuracy}')\n",
    "\n",
    "# Generate the classification report for the overall test predictions\n",
    "report_knn_logo = classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV kNN Model Classification Report\")\n",
    "print(classification_report(y_true_knn_all, y_pred_knn_all, target_names=le.classes_))\n",
    "\n",
    "# Print the confusion matrix in text format\n",
    "conf_matrix = confusion_matrix(y_true_knn_all, y_pred_knn_all)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Print the detailed results\n",
    "for class_name, metrics in report_knn_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier (GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "model_gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_gbc = []\n",
    "y_true_all_gbc = []\n",
    "y_pred_all_gbc = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_gbc.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_gbc.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_gbc.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_gbc.extend(y_test)\n",
    "    y_pred_all_gbc.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_gbc = accuracy_score(y_true_all_gbc, y_pred_all_gbc)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_gbc}')\n",
    "print(\"Leave-One-Group-Out CV GBC Model Classification Report\")\n",
    "report_gbc_logo = classification_report(y_true_all_gbc, y_pred_all_gbc, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_gbc, y_pred_all_gbc, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_gbc = confusion_matrix(y_true_all_gbc, y_pred_all_gbc)\n",
    "df_cm_gbc = pd.DataFrame(cm_logo_gbc, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_gbc)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_gbc_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM (LGBM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LightGBM Classifier\n",
    "model_lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lgbm = []\n",
    "y_true_all_lgbm = []\n",
    "y_pred_all_lgbm = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lgbm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lgbm.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lgbm.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_lgbm.extend(y_test)\n",
    "    y_pred_all_lgbm.extend(y_test_pred)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy_lgbm = accuracy_score(y_true_all_lgbm, y_pred_all_lgbm)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy: {overall_accuracy_lgbm}')\n",
    "print(\"Leave-One-Group-Out CV LGBM Model Classification Report\")\n",
    "report_lgbm_logo = classification_report(y_true_all_lgbm, y_pred_all_lgbm, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_lgbm, y_pred_all_lgbm, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "cm_logo_lgbm = confusion_matrix(y_true_all_lgbm, y_pred_all_lgbm)\n",
    "df_cm_lgbm = pd.DataFrame(cm_logo_lgbm, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(df_cm_lgbm)\n",
    "\n",
    "# Display the detailed results\n",
    "for class_name, metrics in report_lgbm_logo.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis (LDA) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the LDA Classifier\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies_lda = []\n",
    "y_true_all_ldar = []\n",
    "y_pred_all_ldar = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X, y_encoded, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model_lda.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = model_lda.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the accuracy\n",
    "    accuracies_lda.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual values\n",
    "    y_true_all_ldar.extend(y_test)\n",
    "    y_pred_all_ldar.extend(y_test_pred)\n",
    "\n",
    "# Reverse the predicted classes\n",
    "y_pred_all_ldar_reversed = [1 - y for y in y_pred_all_ldar]\n",
    "\n",
    "# Calculate the overall accuracy for the reversed predictions\n",
    "overall_accuracy_lda_reversed = accuracy_score(y_true_all_ldar, y_pred_all_ldar_reversed)\n",
    "\n",
    "print(f'Leave-One-Group-Out CV - Average Test Accuracy (Reversed Classes): {overall_accuracy_lda_reversed}')\n",
    "print(\"Leave-One-Group-Out CV LDA Model Classification Report (Reversed Classes)\")\n",
    "report_lda_logo_reversed = classification_report(y_true_all_ldar, y_pred_all_ldar_reversed, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_true_all_ldar, y_pred_all_ldar_reversed, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix for the reversed predictions\n",
    "cm_logo_lda_reversed = confusion_matrix(y_true_all_ldar, y_pred_all_ldar_reversed)\n",
    "df_cm_lda_reversed = pd.DataFrame(cm_logo_lda_reversed, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix (Reversed Classes):\")\n",
    "print(df_cm_lda_reversed)\n",
    "\n",
    "# Display the detailed results for the reversed predictions\n",
    "for class_name, metrics in report_lda_logo_reversed.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize Logistic Regression model with a different solver\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=10000, solver='liblinear')\n",
    "\n",
    "# Standardize the data (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize Leave-One-Group-Out Cross-Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Initialize lists to store results\n",
    "test_accuracies_logreg = []\n",
    "y_true_all_logreg = []\n",
    "y_pred_all_logreg = []\n",
    "\n",
    "# Apply LOGO-CV\n",
    "for train_index, test_index in logo.split(X_scaled, y, groups):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test samples\n",
    "    y_test_pred = logreg_model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store test accuracies\n",
    "    test_accuracies_logreg.append(accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # Store the prediction and actual value\n",
    "    y_true_all_logreg.extend(y_test)\n",
    "    y_pred_all_logreg.extend(y_test_pred)\n",
    "\n",
    "# Flip the predictions\n",
    "y_pred_lg_flipped = ['Non-Thai' if pred == 'Thai' else 'Thai' for pred in y_pred_all_logreg]\n",
    "\n",
    "# Generate the classification report for the flipped predictions\n",
    "report_logreg_flipped = classification_report(y_true_all_logreg, y_pred_lg_flipped, target_names=le.classes_, output_dict=True)\n",
    "print(\"Leave-One-Group-Out CV Logistic Regression Model (Flipped) Classification Report\")\n",
    "print(classification_report(y_true_all_logreg, y_pred_lg_flipped, target_names=le.classes_))\n",
    "\n",
    "# Generate and display the confusion matrix for the flipped predictions\n",
    "cm_logreg_flipped = confusion_matrix(y_true_all_logreg, y_pred_lg_flipped)\n",
    "df_cm_logreg_flipped = pd.DataFrame(cm_logreg_flipped, index=le.classes_, columns=le.classes_)\n",
    "print(\"Confusion Matrix (Flipped):\")\n",
    "print(df_cm_logreg_flipped)\n",
    "\n",
    "# Display the detailed results for the flipped predictions\n",
    "for class_name, metrics in report_logreg_flipped.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"Class: {class_name}\")\n",
    "        for metric_name, score in metrics.items():\n",
    "            print(f\"{metric_name}: {score}\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {metrics}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have these classification reports stored\n",
    "# classification_report_rf = ...\n",
    "# classification_report_svm = ...\n",
    "# classification_report_et = ...\n",
    "# classification_report_knn = ...\n",
    "# classification_report_gbc = ...\n",
    "# classification_report_lgbm = ...\n",
    "# classification_report_lda = ...\n",
    "# classification_report_logreg = ...\n",
    "\n",
    "# Function to display classification report\n",
    "def display_classification_report(report, model_name):\n",
    "    print(f\"Classification Report for {model_name}\")\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"Class: {label}\")\n",
    "            for metric_name, score in metrics.items():\n",
    "                print(f\"{metric_name}: {score}\")\n",
    "        else:\n",
    "            print(f\"{label}: {metrics}\")\n",
    "        print()\n",
    "\n",
    "# Call the function for each classifier\n",
    "display_classification_report(report_rf_logo, \"Random Forest\")\n",
    "display_classification_report(report_svm1_logo, \"SVM\")\n",
    "display_classification_report(report_et_logo, \"Extra Trees\")\n",
    "display_classification_report(report_knn_logo, \"k-Nearest Neighbors\")\n",
    "display_classification_report(report_gbc_logo, \"Gradient Boosting Classifier\")\n",
    "display_classification_report(report_lgbm_logo, \"LightGBM\")\n",
    "display_classification_report(report_lda_logo_reversed, \"Linear Discriminant Analysis\")\n",
    "display_classification_report(report_logreg_flipped, \"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the true labels and predictions for each classifier stored in the following variables:\n",
    "# y_true_rf, y_pred_rf\n",
    "# y_true_svm, y_pred_svm\n",
    "# y_true_et, y_pred_et\n",
    "# y_true_knn, y_pred_knn\n",
    "# y_true_gbc, y_pred_gbc\n",
    "# y_true_lgbm, y_pred_lgbm\n",
    "# y_true_lda, y_pred_lda\n",
    "# y_true_logreg, y_pred_logreg\n",
    "\n",
    "# y_true_rf2_all, y_pred_rf2_all\n",
    "# y_true_svm2_all,  y_pred_svm2_all\n",
    "# y_true_et_all, y_pred_et_all\n",
    "# y_true_knn_all, y_pred_knn_all\n",
    "# y_true_all_gbc, y_pred_all_gbc\n",
    "# y_true_all_lgbm, y_pred_all_lgbm\n",
    "# y_true_all_ldar, y_pred_all_ldar_reversed\n",
    "# y_true_all_logreg, y_pred_lg_flipped\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = le.classes_\n",
    "\n",
    "# Function to display confusion matrix\n",
    "def display_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Display confusion matrices for each classifier\n",
    "display_confusion_matrix(y_true_rf2_all, y_pred_rf2_all, 'Random Forest Confusion Matrix')\n",
    "display_confusion_matrix(y_true_svm2_all,  y_pred_svm2_all, 'SVM Confusion Matrix')\n",
    "display_confusion_matrix(y_true_et_all, y_pred_et_all, 'Extra Trees Confusion Matrix')\n",
    "display_confusion_matrix(y_true_knn_all, y_pred_knn_all, 'kNN Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_gbc, y_pred_all_gbc, 'Gradient Boosting Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_lgbm, y_pred_all_lgbm, 'LightGBM Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_ldar, y_pred_all_ldar_reversed, 'LDA Confusion Matrix')\n",
    "display_confusion_matrix(y_true_all_logreg, y_pred_lg_flipped, 'Logistic Regression Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Confusion Matrices as Text Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix as a text table\n",
    "def display_confusion_matrix_text(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "    print(title)\n",
    "    print(df_cm)\n",
    "    print()\n",
    "\n",
    "# Display confusion matrices for each classifier as text tables\n",
    "display_confusion_matrix_text(y_true_rf2_all, y_pred_rf2_all, 'Random Forest Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_svm2_all,  y_pred_svm2_all, 'SVM Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_et_all, y_pred_et_all, 'Extra Trees Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_knn_all, y_pred_knn_all, 'kNN Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_gbc, y_pred_all_gbc, 'Gradient Boosting Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_lgbm, y_pred_all_lgbm, 'LightGBM Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_ldar, y_pred_all_ldar_reversed, 'LDA Confusion Matrix')\n",
    "display_confusion_matrix_text(y_true_all_logreg, y_pred_lg_flipped, 'Logistic Regression Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
